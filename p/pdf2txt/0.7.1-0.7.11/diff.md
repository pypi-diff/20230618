# Comparing `tmp/pdf2txt-0.7.1-py3-none-any.whl.zip` & `tmp/pdf2txt-0.7.11-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,34 +1,63 @@
-Zip file size: 75263 bytes, number of entries: 32
--rw-r--r--  2.0 unx     9485 b- defN 21-Jun-16 15:00 pdf2txt/__init__.py
--rw-r--r--  2.0 unx    29783 b- defN 21-Jun-20 16:14 pdf2txt/charts.py
+Zip file size: 277702 bytes, number of entries: 61
+-rw-r--r--  2.0 unx       45 b- defN 23-Jun-18 12:13 pdf2txt/__init__.py
+-rw-r--r--  2.0 unx    31472 b- defN 21-Jul-21 22:41 pdf2txt/charts.py
 -rw-r--r--  2.0 unx     1176 b- defN 20-Dec-25 13:29 pdf2txt/exceptions.py
 -rw-r--r--  2.0 unx    11551 b- defN 21-Jan-05 08:39 pdf2txt/imutils.py
 -rw-r--r--  2.0 unx     1181 b- defN 21-Jun-06 23:05 pdf2txt/settings.py
--rw-r--r--  2.0 unx    42584 b- defN 21-Jun-23 10:53 pdf2txt/table.py
--rw-r--r--  2.0 unx     7676 b- defN 21-Jun-23 10:53 pdf2txt/table_ml.py
--rw-r--r--  2.0 unx    40401 b- defN 21-Jun-22 12:37 pdf2txt/utils.py
--rw-r--r--  2.0 unx       20 b- defN 21-Jun-23 11:24 pdf2txt/version.py
+-rw-r--r--  2.0 unx    49647 b- defN 21-Jul-21 23:39 pdf2txt/table.py
+-rw-r--r--  2.0 unx     7686 b- defN 21-Jul-08 21:55 pdf2txt/table_ml.py
+-rw-r--r--  2.0 unx    40962 b- defN 23-Jun-15 09:28 pdf2txt/utils.py
+-rw-r--r--  2.0 unx       21 b- defN 23-Jun-18 12:15 pdf2txt/version.py
 -rw-r--r--  2.0 unx     9007 b- defN 20-Dec-27 11:51 pdf2txt/visualize.py
 -rw-r--r--  2.0 unx       88 b- defN 21-Jun-16 14:57 pdf2txt/core/__init__.py
--rw-r--r--  2.0 unx     6181 b- defN 21-Jun-23 10:00 pdf2txt/core/component.py
--rw-r--r--  2.0 unx     4639 b- defN 21-Jun-23 10:43 pdf2txt/core/document.py
+-rw-r--r--  2.0 unx     3443 b- defN 21-Jun-24 22:09 pdf2txt/core/component.py
+-rw-r--r--  2.0 unx     5941 b- defN 23-Jun-15 13:17 pdf2txt/core/document.py
 -rw-r--r--  2.0 unx    37088 b- defN 20-Dec-26 12:05 pdf2txt/core/filtering.py
--rw-r--r--  2.0 unx     1957 b- defN 21-Jan-29 17:18 pdf2txt/core/indexer.py
--rw-r--r--  2.0 unx    23165 b- defN 21-Jun-23 10:46 pdf2txt/core/page.py
--rw-r--r--  2.0 unx    23775 b- defN 21-Jun-22 09:55 pdf2txt/core/paragraph.py
+-rw-r--r--  2.0 unx     1959 b- defN 23-Jun-15 13:16 pdf2txt/core/indexer.py
+-rw-r--r--  2.0 unx    31604 b- defN 23-Jun-16 11:37 pdf2txt/core/page.py
+-rw-r--r--  2.0 unx    25431 b- defN 23-Jun-16 13:01 pdf2txt/core/paragraph.py
 -rw-r--r--  2.0 unx     3014 b- defN 21-Jan-27 15:01 pdf2txt/core/search.py
--rw-r--r--  2.0 unx     7722 b- defN 21-Jun-20 22:14 pdf2txt/core/token.py
+-rw-r--r--  2.0 unx     9250 b- defN 21-Jul-25 15:44 pdf2txt/core/token.py
 -rw-r--r--  2.0 unx     1734 b- defN 21-Jun-12 15:30 pdf2txt/core/tree.py
--rw-r--r--  2.0 unx     7047 b- defN 21-Jun-23 10:31 pdf2txt/core/word.py
+-rw-r--r--  2.0 unx    10182 b- defN 21-Jul-25 15:39 pdf2txt/core/word.py
 -rw-r--r--  2.0 unx        0 b- defN 21-Jun-23 11:24 pdf2txt/doc_analyzer/__init__.py
 -rw-r--r--  2.0 unx     5657 b- defN 21-Jun-07 23:33 pdf2txt/doc_analyzer/connected_components.py
--rw-r--r--  2.0 unx     2540 b- defN 21-Jun-23 10:18 pdf2txt/doc_analyzer/image_analyzer.py
--rw-r--r--  2.0 unx     9383 b- defN 21-Jun-23 07:36 pdf2txt/doc_analyzer/imageprocessor.py
--rw-r--r--  2.0 unx     2895 b- defN 21-Jun-17 08:11 pdf2txt/doc_analyzer/img.py
--rw-r--r--  2.0 unx     8915 b- defN 21-Jun-23 07:16 pdf2txt/doc_analyzer/region.py
+-rw-r--r--  2.0 unx     2591 b- defN 23-Jun-14 22:58 pdf2txt/doc_analyzer/image_analyzer.py
+-rw-r--r--  2.0 unx     9439 b- defN 21-Jul-27 20:30 pdf2txt/doc_analyzer/imageprocessor.py
+-rw-r--r--  2.0 unx     3282 b- defN 21-Jun-26 22:15 pdf2txt/doc_analyzer/img.py
+-rw-r--r--  2.0 unx     9037 b- defN 21-Jul-30 12:55 pdf2txt/doc_analyzer/region.py
 -rw-r--r--  2.0 unx     4886 b- defN 21-Jun-12 14:28 pdf2txt/doc_analyzer/text_segmenter.py
--rw-r--r--  2.0 unx      549 b- defN 21-Jun-23 11:24 pdf2txt-0.7.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 21-Jun-23 11:24 pdf2txt-0.7.1.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 21-Jun-23 11:24 pdf2txt-0.7.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2571 b- defN 21-Jun-23 11:24 pdf2txt-0.7.1.dist-info/RECORD
-32 files, 306770 bytes uncompressed, 71195 bytes compressed:  76.8%
+-rw-r--r--  2.0 unx      884 b- defN 23-Jun-18 12:13 pdf2txt/simple_reader/__init__.py
+-rw-r--r--  2.0 unx    14645 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_cmap.py
+-rw-r--r--  2.0 unx    38979 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_encryption.py
+-rw-r--r--  2.0 unx    82095 b- defN 23-Jun-18 12:01 pdf2txt/simple_reader/_page.py
+-rw-r--r--  2.0 unx     1486 b- defN 23-Jun-16 15:09 pdf2txt/simple_reader/_protocols.py
+-rw-r--r--  2.0 unx    77922 b- defN 23-Jun-18 12:01 pdf2txt/simple_reader/_reader.py
+-rw-r--r--  2.0 unx    10628 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_security.py
+-rw-r--r--  2.0 unx    14252 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_utils.py
+-rw-r--r--  2.0 unx       22 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_version.py
+-rw-r--r--  2.0 unx    13154 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/constants.py
+-rw-r--r--  2.0 unx      782 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/errors.py
+-rw-r--r--  2.0 unx    24364 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/filters.py
+-rw-r--r--  2.0 unx     6415 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/pagerange.py
+-rw-r--r--  2.0 unx     1676 b- defN 23-Jun-16 15:17 pdf2txt/simple_reader/types.py
+-rw-r--r--  2.0 unx    18356 b- defN 23-Jun-18 12:01 pdf2txt/simple_reader/xmp.py
+-rw-r--r--  2.0 unx     1720 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_codecs/__init__.py
+-rw-r--r--  2.0 unx   431492 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_codecs/adobe_glyphs.py
+-rw-r--r--  2.0 unx     4269 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_codecs/pdfdoc.py
+-rw-r--r--  2.0 unx     2630 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_codecs/std.py
+-rw-r--r--  2.0 unx     3734 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_codecs/symbol.py
+-rw-r--r--  2.0 unx     3742 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/_codecs/zapfding.py
+-rw-r--r--  2.0 unx     4413 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/generic/__init__.py
+-rw-r--r--  2.0 unx    10065 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/generic/_annotations.py
+-rw-r--r--  2.0 unx    23996 b- defN 23-Jun-18 12:01 pdf2txt/simple_reader/generic/_base.py
+-rw-r--r--  2.0 unx    51426 b- defN 23-Jun-18 12:01 pdf2txt/simple_reader/generic/_data_structures.py
+-rw-r--r--  2.0 unx     4894 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/generic/_fit.py
+-rw-r--r--  2.0 unx     1201 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/generic/_outline.py
+-rw-r--r--  2.0 unx     9439 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/generic/_rectangle.py
+-rw-r--r--  2.0 unx     6272 b- defN 23-Jun-15 12:55 pdf2txt/simple_reader/generic/_utils.py
+-rw-r--r--  2.0 unx      615 b- defN 23-Jun-18 12:16 pdf2txt-0.7.11.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-18 12:16 pdf2txt-0.7.11.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Jun-18 12:16 pdf2txt-0.7.11.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     5294 b- defN 23-Jun-18 12:16 pdf2txt-0.7.11.dist-info/RECORD
+61 files, 1188336 bytes uncompressed, 269308 bytes compressed:  77.3%
```

## zipnote {}

```diff
@@ -78,20 +78,107 @@
 
 Filename: pdf2txt/doc_analyzer/region.py
 Comment: 
 
 Filename: pdf2txt/doc_analyzer/text_segmenter.py
 Comment: 
 
-Filename: pdf2txt-0.7.1.dist-info/METADATA
+Filename: pdf2txt/simple_reader/__init__.py
 Comment: 
 
-Filename: pdf2txt-0.7.1.dist-info/WHEEL
+Filename: pdf2txt/simple_reader/_cmap.py
 Comment: 
 
-Filename: pdf2txt-0.7.1.dist-info/top_level.txt
+Filename: pdf2txt/simple_reader/_encryption.py
 Comment: 
 
-Filename: pdf2txt-0.7.1.dist-info/RECORD
+Filename: pdf2txt/simple_reader/_page.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_protocols.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_reader.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_security.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_utils.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_version.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/constants.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/errors.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/filters.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/pagerange.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/types.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/xmp.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_codecs/__init__.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_codecs/adobe_glyphs.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_codecs/pdfdoc.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_codecs/std.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_codecs/symbol.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/_codecs/zapfding.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/__init__.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_annotations.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_base.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_data_structures.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_fit.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_outline.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_rectangle.py
+Comment: 
+
+Filename: pdf2txt/simple_reader/generic/_utils.py
+Comment: 
+
+Filename: pdf2txt-0.7.11.dist-info/METADATA
+Comment: 
+
+Filename: pdf2txt-0.7.11.dist-info/WHEEL
+Comment: 
+
+Filename: pdf2txt-0.7.11.dist-info/top_level.txt
+Comment: 
+
+Filename: pdf2txt-0.7.11.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pdf2txt/__init__.py

```diff
@@ -1,216 +1 @@
-import warnings
-from pdf2txt.core import *
-#from pdf2txt.pdf_handler import PDFHandler
-#from pdf2txt.utils import validate_input, remove_extra
-
-
-def read_pdf(
-    filepath,
-    pages="1",
-    password=None,
-    flavor="lattice",
-    suppress_stdout=False,
-    layout_kwargs={},
-    **kwargs
-):
-    """Read PDF and return extracted tables.
-    Note: kwargs annotated with ^ can only be used with flavor='stream'
-    and kwargs annotated with * can only be used with flavor='lattice'.
-    Parameters
-    ----------
-    filepath : str
-        Filepath or URL of the PDF file.
-    pages : str, optional (default: '1')
-        Comma-separated page numbers.
-        Example: '1,3,4' or '1,4-end' or 'all'.
-    password : str, optional (default: None)
-        Password for decryption.
-    flavor : str (default: 'lattice')
-        The parsing method to use ('lattice' or 'stream').
-        Lattice is used by default.
-    suppress_stdout : bool, optional (default: True)
-        Print all logs and warnings.
-    layout_kwargs : dict, optional (default: {})
-        A dict of `pdfminer.layout.LAParams <https://github.com/euske/pdfminer/blob/master/pdfminer/layout.py#L33>`_ kwargs.
-    table_areas : list, optional (default: None)
-        List of table area strings of the form x1,y1,x2,y2
-        where (x1, y1) -> left-top and (x2, y2) -> right-bottom
-        in PDF coordinate space.
-    columns^ : list, optional (default: None)
-        List of column x-coordinates strings where the coordinates
-        are comma-separated.
-    split_text : bool, optional (default: False)
-        Split text that spans across multiple cells.
-    flag_size : bool, optional (default: False)
-        Flag text based on font size. Useful to detect
-        super/subscripts. Adds <s></s> around flagged text.
-    strip_text : str, optional (default: '')
-        Characters that should be stripped from a string before
-        assigning it to a cell.
-    row_tol^ : int, optional (default: 2)
-        Tolerance parameter used to combine text vertically,
-        to generate rows.
-    column_tol^ : int, optional (default: 0)
-        Tolerance parameter used to combine text horizontally,
-        to generate columns.
-    process_background* : bool, optional (default: False)
-        Process background lines.
-    line_scale* : int, optional (default: 15)
-        Line size scaling factor. The larger the value the smaller
-        the detected lines. Making it very large will lead to text
-        being detected as lines.
-    copy_text* : list, optional (default: None)
-        {'h', 'v'}
-        Direction in which text in a spanning cell will be copied
-        over.
-    shift_text* : list, optional (default: ['l', 't'])
-        {'l', 'r', 't', 'b'}
-        Direction in which text in a spanning cell will flow.
-    line_tol* : int, optional (default: 2)
-        Tolerance parameter used to merge close vertical and horizontal
-        lines.
-    joint_tol* : int, optional (default: 2)
-        Tolerance parameter used to decide whether the detected lines
-        and points lie close to each other.
-    threshold_blocksize* : int, optional (default: 15)
-        Size of a pixel neighborhood that is used to calculate a
-        threshold value for the pixel: 3, 5, 7, and so on.
-        For more information, refer `OpenCV's adaptiveThreshold <https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#adaptivethreshold>`_.
-    threshold_constant* : int, optional (default: -2)
-        Constant subtracted from the mean or weighted mean.
-        Normally, it is positive but may be zero or negative as well.
-        For more information, refer `OpenCV's adaptiveThreshold <https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#adaptivethreshold>`_.
-    iterations* : int, optional (default: 0)
-        Number of times for erosion/dilation is applied.
-        For more information, refer `OpenCV's dilate <https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#dilate>`_.
-    resolution* : int, optional (default: 300)
-        Resolution used for PDF to PNG conversion.
-    Returns
-    -------
-    tables : camelot.core.TableList
-    """
-    if flavor not in ["lattice", "stream"]:
-        raise NotImplementedError(
-            "Unknown flavor specified." " Use either 'lattice' or 'stream'"
-        )
-
-    with warnings.catch_warnings():
-        if suppress_stdout:
-            warnings.simplefilter("ignore")
-
-        validate_input(kwargs, flavor=flavor)
-        p = PDFHandler(filepath, pages=pages, password=password)
-        kwargs = remove_extra(kwargs, flavor=flavor)
-        pages = p.parse(
-            flavor=flavor,
-            suppress_stdout=suppress_stdout,
-            layout_kwargs=layout_kwargs,
-            **kwargs
-        )
-        return pages
-
-
-def parse_pdf_from_layout(
-    filepath,
-    pages="1",
-    password=None,
-    flavor="lattice",
-    suppress_stdout=False,
-    layout_kwargs={},
-    **kwargs
-):
-    """Read PDF and return extracted tables.
-    Note: kwargs annotated with ^ can only be used with flavor='stream'
-    and kwargs annotated with * can only be used with flavor='lattice'.
-    Parameters
-    ----------
-    filepath : str
-        Filepath or URL of the PDF file.
-    pages : str, optional (default: '1')
-        Comma-separated page numbers.
-        Example: '1,3,4' or '1,4-end' or 'all'.
-    password : str, optional (default: None)
-        Password for decryption.
-    flavor : str (default: 'lattice')
-        The parsing method to use ('lattice' or 'stream').
-        Lattice is used by default.
-    suppress_stdout : bool, optional (default: True)
-        Print all logs and warnings.
-    layout_kwargs : dict, optional (default: {})
-        A dict of `pdfminer.layout.LAParams <https://github.com/euske/pdfminer/blob/master/pdfminer/layout.py#L33>`_ kwargs.
-    table_areas : list, optional (default: None)
-        List of table area strings of the form x1,y1,x2,y2
-        where (x1, y1) -> left-top and (x2, y2) -> right-bottom
-        in PDF coordinate space.
-    columns^ : list, optional (default: None)
-        List of column x-coordinates strings where the coordinates
-        are comma-separated.
-    split_text : bool, optional (default: False)
-        Split text that spans across multiple cells.
-    flag_size : bool, optional (default: False)
-        Flag text based on font size. Useful to detect
-        super/subscripts. Adds <s></s> around flagged text.
-    strip_text : str, optional (default: '')
-        Characters that should be stripped from a string before
-        assigning it to a cell.
-    row_tol^ : int, optional (default: 2)
-        Tolerance parameter used to combine text vertically,
-        to generate rows.
-    column_tol^ : int, optional (default: 0)
-        Tolerance parameter used to combine text horizontally,
-        to generate columns.
-    process_background* : bool, optional (default: False)
-        Process background lines.
-    line_scale* : int, optional (default: 15)
-        Line size scaling factor. The larger the value the smaller
-        the detected lines. Making it very large will lead to text
-        being detected as lines.
-    copy_text* : list, optional (default: None)
-        {'h', 'v'}
-        Direction in which text in a spanning cell will be copied
-        over.
-    shift_text* : list, optional (default: ['l', 't'])
-        {'l', 'r', 't', 'b'}
-        Direction in which text in a spanning cell will flow.
-    line_tol* : int, optional (default: 2)
-        Tolerance parameter used to merge close vertical and horizontal
-        lines.
-    joint_tol* : int, optional (default: 2)
-        Tolerance parameter used to decide whether the detected lines
-        and points lie close to each other.
-    threshold_blocksize* : int, optional (default: 15)
-        Size of a pixel neighborhood that is used to calculate a
-        threshold value for the pixel: 3, 5, 7, and so on.
-        For more information, refer `OpenCV's adaptiveThreshold <https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#adaptivethreshold>`_.
-    threshold_constant* : int, optional (default: -2)
-        Constant subtracted from the mean or weighted mean.
-        Normally, it is positive but may be zero or negative as well.
-        For more information, refer `OpenCV's adaptiveThreshold <https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#adaptivethreshold>`_.
-    iterations* : int, optional (default: 0)
-        Number of times for erosion/dilation is applied.
-        For more information, refer `OpenCV's dilate <https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#dilate>`_.
-    resolution* : int, optional (default: 300)
-        Resolution used for PDF to PNG conversion.
-    Returns
-    -------
-    tables : camelot.core.TableList
-    """
-    if flavor not in ["lattice", "stream"]:
-        raise NotImplementedError(
-            "Unknown flavor specified." " Use either 'lattice' or 'stream'"
-        )
-
-    with warnings.catch_warnings():
-        if suppress_stdout:
-            warnings.simplefilter("ignore")
-
-        validate_input(kwargs, flavor=flavor)
-        p = PDFHandler(filepath, pages=pages, password=password)
-        kwargs = remove_extra(kwargs, flavor=flavor)
-        pages = p.parse(
-            flavor=flavor,
-            suppress_stdout=suppress_stdout,
-            layout_kwargs=layout_kwargs,
-            **kwargs
-        )
-        return pages
+from pdf2txt.simple_reader import PdfDocument
```

## pdf2txt/charts.py

```diff
@@ -1,13 +1,13 @@
 from pdf2txt.utils import cluster_objects, get_type, get_partially_overlapping_objects, intersecting_edges, edge_intersect_text, \
     parse_value, is_ovarlaping_with_objects, cluster_objects2, get_partially_touching_objects, vertical_overlap_with_list, horizontal_overlap_with_list, vertical_overlap, horizontal_overlap
 from statistics import mean
 from pdf2txt.utils import BoundingBox, get_widthin_BoundingBox, get_BoundingBox_from_objects, contains_objects
 import pandas as pd
-from itertools import compress
+from itertools import compress, combinations
 from collections import Counter
 from pdf2txt.doc_analyzer.img import show_rects_and_wait
 from math import isclose, ceil
 
 
 class Chart(BoundingBox):
 
@@ -132,22 +132,26 @@
 #         rect.fill and (200 > rect.width > 0.5 and 200 > rect.height > 0.5)], key=lambda l: l.top)
     rect_for_graphs=rectangles
 
 
 #    show_rects_and_wait(page.lines, image=page.image.copy())
     edges = rects_to_edges(rect_for_graphs,rectangles_, page.tokens, rect_threshold=rect_threshold, page=page)
 
-    graphs=[]
+    charts=[]
     for e in edges['v']: #horizontal graphs
-        graphs.append(extract_chart_area(e, page, rect_for_graphs,graph_type='h'))
+        charts.append(extract_chart_area(e, page,graph_type='h'))
 
     for e in  edges['h']:
-        graphs.append(extract_chart_area(e, page, rect_for_graphs, graph_type='v'))
+        charts.append(extract_chart_area(e, page, graph_type='v'))
 
-    return graphs
+    for a, b in combinations(charts, 2):
+        if a.contains(b):
+            charts.remove(b)
+#    show_rects_and_wait(charts, image=page.page_image.copy())
+    return charts
 
 
 def separate_edges_v(edge, min_separation=4, min_gap=4, min_separation_size=60):
 
     edge['components'] = sorted(edge['components'], key=lambda e: e.top)
     # if len(edge['components'])<3:
     #     return [edge]
@@ -553,15 +557,15 @@
     edge['bbox'] = BoundingBox(left=min(rect.left for rect in edge['components']),
                                right=max(rect.right for rect in edge['components']),
                                top=min(rect.top for rect in edge['components']),
                                bottom=max(rect.bottom for rect in edge['components']))
 
     return edge
 
-def extract_chart_area(edge, page, rectangles, graph_type):
+def extract_chart_area(edge, page, graph_type):
 
 #    show_rects_and_wait([edge['bbox']], image=page.image.copy())
     if edge["axis_line"]:
         bbox = [edge['bbox'],edge["axis_line"]]
     else:
         bbox= [edge['bbox']]
     edge['bbox'] = BoundingBox(left=min([b.left for b in bbox]), top=min(([b.top for b in bbox])), right=max([b.right for b in bbox]), bottom=max(([b.bottom for b in bbox])))
@@ -571,57 +575,104 @@
     bbox_right = BoundingBox(left=bbox.right, top=bbox.top, right=bbox.right, bottom=bbox.bottom)
     bbox_top = BoundingBox(left=bbox.left, top=bbox.top, right=bbox.right, bottom=bbox.top)
     bbox_bottom = BoundingBox(left=bbox.left, top=bbox.bottom, right=bbox.right, bottom=bbox.bottom)
 
 
 #    show_rects_and_wait([edge['bbox']], image=page.image.copy())
 
-    step_size=10
+    step_size=1
+    x_step_size=2
+    y_step_size=2
+    x_left_multiplier=1 #allow to reach further to left in order to find column labels in case fo horizontal bar charts
+    y_bottom_multiplier=1 #idem for vertical bar charts
+    if graph_type=='h':
+        x_step_size*=5
+        x_left_multiplier=2
+    if graph_type=="v":
+        y_step_size*=5
+        y_bottom_multiplier=2
+
+
+    edge['bbox'].top -= y_step_size
+    bbox_top.top -= y_step_size
+    bbox_top.bottom -= y_step_size
+
+
+    edge['bbox'].left -= x_left_multiplier*x_step_size
+    bbox_left.left -= x_left_multiplier*x_step_size
+    bbox_left.right -= x_left_multiplier*x_step_size
+
+    edge['bbox'].right += x_step_size
+    bbox_right.right += x_step_size
+    bbox_right.left += x_step_size
+
+    edge['bbox'].bottom += y_bottom_multiplier*y_step_size
+    bbox_bottom.bottom += y_bottom_multiplier*y_step_size
+    bbox_bottom.top += y_bottom_multiplier*y_step_size
 
-    edge['bbox'].top -= step_size
-    bbox_top.top -= step_size
-    bbox_top.bottom -= step_size
-
-
-    edge['bbox'].left -= step_size
-    bbox_left.left -= step_size
-    bbox_left.right -= step_size
-
-    edge['bbox'].right += step_size
-    bbox_right.right += step_size
-    bbox_right.left += step_size
-
-    edge['bbox'].bottom += step_size
-    bbox_bottom.bottom += step_size
-    bbox_bottom.top += step_size
 
+#    show_rects_and_wait([edge['bbox']], image=page.page_image.copy())
     while is_ovarlaping_with_objects(bbox_top, page.tokens):
         edge['bbox'].top -= step_size
         bbox_top.top -= step_size
         bbox_top.bottom -= step_size
-#        show_rects_and_wait([edge['bbox']], image=page.image.copy())
-
+#        show_rects_and_wait([edge['bbox']], image=page.page_image.copy())
+    nb_tries=1
+    if graph_type=='h':
+        while not is_ovarlaping_with_objects(bbox_left, page.tokens) and nb_tries<10:
+            edge['bbox'].left -= step_size
+            bbox_left.left -= step_size
+            bbox_left.right -= step_size
+            nb_tries+=1
     while is_ovarlaping_with_objects(bbox_left, page.tokens):
         edge['bbox'].left -= step_size
         bbox_left.left -= step_size
         bbox_left.right -= step_size
- #       show_rects_and_wait([edge['bbox']], image=page.image.copy())
+#        show_rects_and_wait([edge['bbox']], image=page.page_image.copy())
 
 
     while is_ovarlaping_with_objects(bbox_right, page.tokens):
         edge['bbox'].right += step_size
         bbox_right.right += step_size
         bbox_right.left += step_size
- #       show_rects_and_wait([edge['bbox']], image=page.image.copy())
+#        show_rects_and_wait([edge['bbox']], image=page.page_image.copy())
+
 
+    nb_tries=1
+    if graph_type=='v':
+        while not is_ovarlaping_with_objects(bbox_left, page.tokens) and nb_tries<10:
+            edge['bbox'].bottom += step_size
+            bbox_bottom.bottom += step_size
+            bbox_bottom.top += step_size
+            nb_tries+=1
     while is_ovarlaping_with_objects(bbox_bottom, page.tokens):
         edge['bbox'].bottom += step_size
         bbox_bottom.bottom += step_size
         bbox_bottom.top += step_size
-#        show_rects_and_wait([edge['bbox']], image=page.image.copy())
+#        show_rects_and_wait([edge['bbox']], image=page.page_image.copy())
+
+
+
+    edge['bbox'].top += step_size
+    bbox_top.top += step_size
+    bbox_top.bottom += step_size
+
+
+    edge['bbox'].left += step_size
+    bbox_left.left += step_size
+    bbox_left.right += step_size
+
+    edge['bbox'].right -= step_size
+    bbox_right.right -= step_size
+    bbox_right.left -= step_size
+
+    edge['bbox'].bottom -= step_size
+    bbox_bottom.bottom -= step_size
+    bbox_bottom.top -= step_size
+
 
     edge['axis'].top=edge['bbox'].top
     edge['axis'].bottom=edge['bbox'].bottom
 
 #    edge['components']=get_partially_overlapping_objects(edge['bbox'], rectangles)
     return Chart(left=edge['bbox'].left, right=edge['bbox'].right, top=edge['bbox'].top, bottom=edge['bbox'].bottom, page=page, graph_type=graph_type, **edge)
 
@@ -692,30 +743,30 @@
 
     i = 0
     while not is_ovarlaping_with_objects(bbox_bottom, page.tokens) and i < NB_POINTS/2:
         edge['bbox'].bottom += 1
         bbox_bottom.bottom += 1
         bbox_bottom.top += 1
         i += 1
-        show_rects_and_wait([edge['bbox']], image=page.image.copy())
+        #show_rects_and_wait([edge['bbox']], image=page.image.copy())
     if i == NB_POINTS:
         # we did not find any text redude the area by 10
         edge['bbox'].bottom -= NB_POINTS/4
     if i == 0:
         edge['bbox'].bottom += NB_POINTS/4
         bbox_bottom.bottom += NB_POINTS/4
         bbox_bottom.top += NB_POINTS/4
     if i < NB_POINTS:
         # once you touch text continue until you passed it
 
         while is_ovarlaping_with_objects(bbox_bottom, page.tokens):
             edge['bbox'].bottom += 1
             bbox_bottom.bottom += 1
             bbox_bottom.top += 1
-            show_rects_and_wait([edge['bbox']], image=page.image.copy())
+            #show_rects_and_wait([edge['bbox']], image=page.image.copy())
 
     while is_ovarlaping_with_objects(
             BoundingBox(left=edge['bbox'].right, top=edge['bbox'].top, right=edge['bbox'].right,
                         bottom=edge['bbox'].bottom), page.tokens):
         edge['bbox'].right += 1
         bbox_bottom.right += 1
         bbox_bottom.left += 1
```

## pdf2txt/table.py

```diff
@@ -3,15 +3,15 @@
 from collections import Counter
 from pdf2txt.core.token import Token
 import numpy as np
 import re
 from pdf2txt.table_ml import extract_table
 import pandas as pd
 from . import utils
-from pdf2txt.doc_analyzer.img import show_rects_and_wait
+from pdf2txt.doc_analyzer.img import show_rects_and_wait, show_and_wait
 from itertools import chain, zip_longest
 from .exceptions import (
     TableExtractionError,
     NoTokenFoundError,
     MultipleTokensFoundError,
     InvalidTableError,
     InvalidTableHeaderError,
@@ -23,151 +23,169 @@
 DEFAULT_MIN_WORDS_VERTICAL = 3
 DEFAULT_MIN_WORDS_HORIZONTAL = 3
 
 from copy import copy
 
 
 class Table(object):
-    def __init__(self, page, textlines=None, rect=None, paragraph=None, settings={}):
+    def __init__(self, region, textlines=None, rect=None, paragraph=None, settings={}):
 
         if textlines == None and rect == None:
             raise Exception(
                 "Incomplete infromation for the table. You should give either a list of tokens or a bounding box coordinates")
-        self.page = page
+        self.region = region
         self.settings = dict(DEFAULT_TABLE_SETTINGS)
         self.settings.update(settings)
-        self.top=-1
-        self.bottom=-1
-        self.right=-1
-        self.left=-1
-        self.interline=-1
-        self.area=rect
+        self.interline = -1
+        self.area = rect
         self.paragraph = paragraph
-        self.from_table_region_only=False
+        self.from_table_region_only = False
         if textlines:
             self.textlines = textlines
             self.settings["edge_min_length"] = max(l[-1].right - l[0].left for l in self.textlines)
         else:
-            self.textlines=utils.find_line_structure(utils.get_widthin_BoundingBox(page.tokens, rect))
+
+            self.textlines = utils.find_line_structure(utils.get_widthin_BoundingBox(region.tokens, rect))
             self.from_table_region_only = True
 
         self._data = []
         self.df = None
 
         self._nb_headers = 1
         self.get_edges()
 
-
     @property
     def bbox(self):
-        return utils.BoundingBox(
-            left=min(map(itemgetter(0), self._data)),
-            top=min(map(itemgetter(1), self._data)),
-            right=max(map(itemgetter(2), self._data)),
-            bittom=max(map(itemgetter(3), self._data))
-        )
+        if self.area is not None:
+            return self.area
+        return utils.get_BoundingBox_from_objects([t for line in self.textlines for t in line])
+
+    @property
+    def top(self):
+        return self.bbox.top
+
+    @property
+    def left(self):
+        return self.bbox.left
+
+    @property
+    def right(self):
+        return self.bbox.right
+
+    @property
+    def bottom(self):
+        return self.bbox.bottom
 
     def vertically_in_line_with(self, token, linelist, tolerance: float = 0.0):
 
         tolerance = min(token.width / 2, tolerance)
         bounding_box = utils.BoundingBox(
             left=token.left - tolerance,
             right=token.right + tolerance,
-            top=self.page.top,
-            bottom=self.page.bottom,
+            top=self.region.top,
+            bottom=self.region.bottom,
         )
         results = set()
 
         for line in linelist:
             for tok in line:
                 if tok.partially_within(bounding_box):
                     results.add(tok)
         return frozenset(results)
 
     def get_edges(self):
 
-        v = utils.filter_edges(self.page.edges, "v")
+        v = utils.filter_edges(self.region.edges, "v")
 
-        hh = self.page.horizontal_edges
-#        show_rects_and_wait(hh, self.page.parent_page.image.copy())
+        hh = self.region.horizontal_edges
+        #show_rects_and_wait(hh, self.region.parent_page.page_image.copy())
         hh = utils.join_collated_h_edges(hh)
 
-        if self.area is not None:
-            hh=[l for l in hh if l.top >= min(self.paragraph[0][0].top, self.area.top) and l.bottom <= max(self.paragraph[-1][0].bottom, self.area.bottom)]
+        if self.area is not None and self.paragraph is not None:
+            hh = [l for l in hh if l.top >= min(self.paragraph[0][0].top, self.area.top) and l.bottom <= max(
+                self.paragraph[-1][0].bottom, self.area.bottom)]
 
- #       show_rects_and_wait(hh, self.page.parent_page.image.copy())
+        #       show_rects_and_wait(hh, self.page.parent_page.image.copy())
 
         left_right = utils.cluster_objects2(hh, ["left", "right"], rel_tol=0, abs_tol=1)
-        h=[]
+        h = []
         if left_right:
-
             h = max(left_right, key=lambda x: len(x))
-#        if len(utils.get_partially_overlapping_objects(utils.get_BoundingBox_from_objects([t for line in self.textlines for t in line]), h)) >= max(1, len(self.textlines)-3):
-        self._edges_h=sorted(h, key=lambda e: e.top)
+        #        if len(utils.get_partially_overlapping_objects(utils.get_BoundingBox_from_objects([t for line in self.textlines for t in line]), h)) >= max(1, len(self.textlines)-3):
+        self._edges_h = sorted(h, key=lambda e: e.top)
         split_index = -1
-        if len(self._edges_h)>len(self.textlines)+2:# we may have been too agressive and selected too many lines.
-            nb_tokens=[len(l) for l in self.page.text_lines]
-            for i in range(0, len(nb_tokens)-2):
-                if nb_tokens[i]==1 and nb_tokens[i+1]==1: #ugly fix
-                    split_index=i
+        if len(self._edges_h) > len(self.textlines) + 2:  # we may have been too agressive and selected too many lines.
+            nb_tokens = [len(l) for l in self.region.text_lines]
+            for i in range(0, len(nb_tokens) - 2):
+                if nb_tokens[i] == 1 and nb_tokens[i + 1] == 1:  # ugly fix
+                    split_index = i
                     break
-            if split_index>0:
-                y_cut_off=self.page.text_lines[i][0].top
-                self._edges_h=[l for l in self._edges_h if l.bottom < y_cut_off]
+            if split_index > 0:
+                y_cut_off = self.region.text_lines[i][0].top
+                self._edges_h = [l for l in self._edges_h if l.bottom < y_cut_off]
         self._edges_v = v
 
     def horizontally_in_line(self, row, rows):
 
         if len(rows) == 0:
             return None
 
         bounding_box = utils.BoundingBox(
-            left=self.page.left,
-            right=self.page.right,
+            left=self.region.left,
+            right=self.region.right,
             top=row.top,
             bottom=row.bottom,
         )
 
         for r in rows:
             for token in list(r):
                 if token.partially_within(bounding_box):
                     return frozenset(r)
         return None
 
     def horizontally_within_lines(self, line_bottom, line_top, nbcols):
 
         if line_top is not None:
             bounding_box = utils.BoundingBox(
-                left=self.page.left,
-                right=self.page.right,
+                left=self.region.left,
+                right=self.region.right,
                 top=line_top.top,
                 bottom=line_bottom.bottom,
             )
 
             ll = [line for line in self.textlines if line[0].within(bounding_box)]
 
             if ll == []:
                 ll = [self.textlines[0]]
-            if len(ll)>1 and all([len(a)==nbcols for a in ll]):
+            if len(ll) > 1 and all([len(a) == nbcols for a in ll]):
                 return ll
 
         else:
             ll = [line for line in self.textlines if line[0].top > line_bottom.bottom]
-        return [[item for sublist in  ll for item in sublist]]
+        return [[item for sublist in ll for item in sublist]]
 
     def extract(self):
-
-        if 2 < len(self._edges_h)<2*(len(self.textlines)+1):
-            return self.extract_from_lines()
-        elif len(self._edges_h)>2*(len(self.textlines)+1) and self.area is not None:
-            self._edges_h=[e for e in self._edges_h if e.top>=self.area.top and e.bottom<=self.area.bottom]
-            if len(self._edges_h) > len(self.textlines):
+        if self.region is not None:
+            self._data = extract_table_from_rects(self.region)
+            if self._data:
+                objects = [c for row in self._data for c in row]
+                objects = [o for l in objects for o in l]
+
+                self.area = utils.get_BoundingBox_from_objects(objects)
+                self._data = [[tokens_to_string(c) for c in row] for row in self._data]
+                return self
+        if not self._data:
+            if 2 < len(self._edges_h) < 2 * (len(self.textlines) + 1):
                 return self.extract_from_lines()
+            elif len(self._edges_h) > 2 * (len(self.textlines) + 1) and self.area is not None:
+                self._edges_h = [e for e in self._edges_h if e.top >= self.area.top and e.bottom <= self.area.bottom]
+                if len(self._edges_h) > len(self.textlines):
+                    return self.extract_from_lines()
 
-        return self.extract_from_text()
+            return self.extract_from_text()
 
     def extract_from_text(self):
         """
         Returns tokens structured as a table.
 
         Given an TokenList, tries to extract a structured table by examining which
         tokens are aligned. There must be a clear gap between each row and between each
@@ -178,134 +196,132 @@
         yet supported.
 
         Returns:
             list[list]: a list of rows, which are lists of PDFTokens or strings
                 (depending on the value of as_text).
         """
 
-        guess_nb_cols_most_common = Counter(len(l) for l in self.textlines if len(l)>1).most_common(1)
+        guess_nb_cols_most_common = Counter(len(l) for l in self.textlines if len(l) > 1).most_common(1)
 
-        nb_cols_cutoff= int(len(self.textlines)/2) if len(self.textlines)>=4 else 2
+        nb_cols_cutoff = int(len(self.textlines) / 2) if len(self.textlines) >= 4 else 2
 
-        if guess_nb_cols_most_common ==[] or guess_nb_cols_most_common[0][1]<nb_cols_cutoff:
+        if guess_nb_cols_most_common == [] or guess_nb_cols_most_common[0][1] < nb_cols_cutoff:
             return None
 
         else:
-            ncols=guess_nb_cols_most_common[0][0]
+            ncols = guess_nb_cols_most_common[0][0]
 
-        if ncols==1:
+        if ncols == 1:
             return None
 
-        if len(self.textlines[-1])==1:
-            self.textlines=self.textlines[:-1]
-
-        while len(self.textlines[0])==1:
-            self.textlines=self.textlines[1:]
+        if len(self.textlines[-1]) == 1:
+            self.textlines = self.textlines[:-1]
 
+        while len(self.textlines[0]) == 1:
+            self.textlines = self.textlines[1:]
 
-        self._data=extract_table(self.textlines)
+        self._data = extract_table(self.textlines)
 
         #        self._validate_table_shape()
         return self
 
     def post_process_token(self, line):
 
         # split list of dates into separate tokens:
         regex = r"(\d{2}[\/\.-]\d{2}[\/\.-]\d{2}\s?)"
-        new_line=[]
+        new_line = []
         for token in line:
             text = token.Text
             matches = re.finditer(regex, text)
 
             indices = []
             nb_matches = 0
             for matchNum, match in enumerate(matches, start=1):
                 nb_matches += 1
 
             if nb_matches > 1:
                 words = [w for w in token.original_words]
 
-                new_line.extend([Token(w.original_word, token.page) for w in words])
+                new_line.extend([Token(w, token.page) for w in words])
             else:
                 new_line.append(token)
         return new_line
 
     def extract_from_textlines(self, rows, token_lines):
-        self._data=extract_table(rows)
+        self._data = extract_table(rows)
         return self
 
     def fix_text_lines(self, textlines):
 
         for line in textlines:
-            if len(line)<=self.ncols:
+            if len(line) <= self.ncols:
                 continue
-            while len(line)>self.ncols:
-                separations=[]
-                for i in range(0, len(line)-1):
-                    separations.append(line[i+1].left-line[i].right)
-                    to_combine=separations.index(min(separations))
-                line[to_combine].combine(line[to_combine+1])
-                line[to_combine].right=line[to_combine+1].right
-                del line[to_combine+1]
+            while len(line) > self.ncols:
+                separations = []
+                for i in range(0, len(line) - 1):
+                    separations.append(line[i + 1].left - line[i].right)
+                    to_combine = separations.index(min(separations))
+                line[to_combine].combine(line[to_combine + 1])
+                line[to_combine].right = line[to_combine + 1].right
+                del line[to_combine + 1]
         return textlines
 
     def extract_from_lines(self):
         bbox = utils.get_BoundingBox_from_objects(self._edges_h)
         bbox.bottom += 10
 
-        if (self.textlines is not None and len(self.textlines)>0) and self._edges_h[0].top > self.textlines[0][0].top:
+        if (self.textlines is not None and len(self.textlines) > 0) and self._edges_h[0].top > self.textlines[0][0].top:
             bbox.top = self.textlines[0][0].top
         if not self.from_table_region_only:
-            self.textlines = [self.post_process_token(line) for line in self.page.text_lines if
-                                line[0].bottom >= bbox.top and line[0].top <= bbox.bottom]
+            self.textlines = [self.post_process_token(line) for line in self.region.text_lines if
+                              line[0].bottom >= bbox.top and line[0].top <= bbox.bottom]
             self._edges_h = [e for e in self._edges_h if
                              e.top > self.textlines[0][0].top - 10 and e.bottom < self.textlines[-1][0].bottom + 10]
         if self.textlines == []:
             return None
 
-
-        if len(self._edges_h)<=2:
+        if len(self._edges_h) <= 2:
             return self.extract_from_text()
-        col_sizes=[len(line) for line in self.textlines if len(line) > 1]
-        if len(col_sizes)>1:
-            self.ncols = Counter([len(line) for line in self.textlines if len(line)>1]).most_common(1)[0][0]
+        col_sizes = [len(line) for line in self.textlines if len(line) > 1]
+        if len(col_sizes) > 1:
+            self.ncols = Counter([len(line) for line in self.textlines if len(line) > 1]).most_common(1)[0][0]
         else:
             return None
-        if self.ncols==1:
+        if self.ncols == 1:
             return None
-        self.textlines=self.fix_text_lines(self.textlines)
-        while len(self.textlines[0])==1:
-            self.textlines=self.textlines[1:]
+        self.textlines = self.fix_text_lines(self.textlines)
+        while len(self.textlines[0]) == 1:
+            self.textlines = self.textlines[1:]
 
-        while len(self.textlines[-1])==1:
-            self.textlines=self.textlines[:-1]
+        while len(self.textlines[-1]) == 1:
+            self.textlines = self.textlines[:-1]
 
         rows = []
 
         z = zip(self._edges_h[1:], self._edges_h[:-1])
-        header=[]
+        header = []
         for i, (b, t) in enumerate(z):
-#            show_rects_and_wait([b, t], self.page.parent_page.image.copy())
+            #            show_rects_and_wait([b, t], self.page.parent_page.image.copy())
             if header == []:
                 if t.top > self.textlines[0][0].bottom:
                     header = [tl for tl in self.textlines if tl[0].top < self._edges_h[0].top]
 
                     rows.extend(self._fix_header_rows(header, self.ncols))
-                elif b.top > (self.textlines[0][0].bottom+self.textlines[0][0].top)/2:
+                elif b.top > (self.textlines[0][0].bottom + self.textlines[0][0].top) / 2:
                     header = self.horizontally_within_lines(b, t, self.ncols)
                     rows.extend(self._fix_header_rows(header, self.ncols))
             else:
                 row = self.horizontally_within_lines(b, t, self.ncols)
                 if row and row not in rows:
                     rows.extend(row)
 
         last_row = self.horizontally_within_lines(b, None, self.ncols)
-        if last_row !=[[]] and len(last_row[0]) >= (int(self.ncols*0.7) if self.ncols >= 3 else self.ncols-1):
+        if last_row != [[]] and len(last_row[0]) >= (int(self.ncols * 0.7) if self.ncols >= 3 else self.ncols - 1):
             rows.extend(last_row)
-        elif last_row !=[[]]:
+        elif last_row != [[]]:
             self.textlines = self.textlines[:-1]
 
         return self.extract_from_textlines(rows, self.textlines)
 
     def _validate_table_shape(self):
         """
         Checks that all rows (and therefore all columns) are the same length.
@@ -337,18 +353,19 @@
 
         if guess_nb_cols < 2:
             return False
 
         # only a subset of columns in a pragraph form a table
         rows = []
 
-        rows_idx=[i for i,r in enumerate(paragraph) if max(guess_nb_cols-2, 2)<=len(r)<=guess_nb_cols+1]
+        rows_idx = [i for i, r in enumerate(paragraph) if max(guess_nb_cols - 2, 2) <= len(r) <= guess_nb_cols + 1]
 
+        table_lines = paragraph[min(rows_idx):max(rows_idx) + 1]
 
-        return paragraph[min(rows_idx):max(rows_idx)+1]
+        return table_lines
 
     def _fix_rows(self, rows, pdflines) -> None:
         """
         Sometimes a token may span over multiple rows. For example:
         ---------
         | A | B |
         ----|   |
@@ -409,30 +426,30 @@
             # No elements are in multiple cols, return.
             return cols
 
         # We sort by looking at all the elements and choosing the element which starts
         # most to the right. The ones with elements which start most to the right
         # will be later on in the sorted list.
         sorted_columns = sorted(
-            cols, key = lambda col: (max([elem.left for elem in col]),-len([e for e in col]))
+            cols, key=lambda col: (max([elem.left for elem in col]), -len([e for e in col]))
         )
         for element in [token for line in tokenlines for token in line]:
             num_cols = sum(element in col for col in cols)
             if num_cols == 1:
                 continue
             # If we reach here, we've found an element in multiple cols.
 
             cols_with_element = [col for col in cols if element in col]
             sorted_cols_with_element = sorted(
                 cols_with_element, key=lambda col: sorted_columns.index(col)
             )
             # Remove the element from all but the first col.
             for col in sorted_cols_with_element[1:]:
                 cols.remove(col)
-                new_col=set(copy(col))
+                new_col = set(copy(col))
                 new_col.remove(element)
                 if new_col:
                     cols.add(frozenset(new_col))
                     # Update sorted columns
                     sorted_columns = [
                         new_col if some_col == col else some_col
                         for some_col in sorted_columns
@@ -454,27 +471,31 @@
 
         if not isinstance(header[0], list):
             return header
         if len(header) == 1:
             return header
 
         header2 = []
-        start_index=0
+        start_index = 0
         header2.append([Token.copy(h) for h in header[-1]])
-        if len(header2[0])==ncols:
-            start_index=1
+        if len(header2[0]) == ncols:
+            start_index = 1
 
         # if the first row is right justified than the first row is not a header row otherwise it is considered as header row
         for i in reversed(range(1, len(header))):
             next_row_used = False
             for token in header[i - 1][start_index:]:
-                if len(header[i][start_index:])>2 and token.left - tolerance > min(t.left for t in header[i][start_index:]) and(len(header[i - 1]) == len(header2[-1]) or len(header[i - 1]) == len(header[i])):  # not left justified or as many header as the last row
+                if len(header[i][start_index:]) > 2 and token.left - tolerance > min(
+                        t.left for t in header[i][start_index:]) and (
+                        len(header[i - 1]) == len(header2[-1]) or len(header[i - 1]) == len(
+                        header[i])):  # not left justified or as many header as the last row
                     for t in header[i - 1]:
                         for j in range(start_index, len(header2[-1])):
-                            if t.left + tolerance >= header2[-1][j].left and t.right - tolerance <= header2[-1][j].right:
+                            if t.left + tolerance >= header2[-1][j].left and t.right - tolerance <= header2[-1][
+                                j].right:
                                 t_c = Token.copy(t)
                                 header2[-1][j] = t_c.combine(header2[-1][j])
                                 next_row_used = True
                     break
                 else:
                     break
             if not next_row_used:
@@ -490,30 +511,29 @@
                 for h in header2[-1]:
                     if h.left >= header[i - 1][-1].left:
                         h_item = Token.copy(header[i - 1][-1])
 
                         h_item.left = h.left
                         h_item.right = h.right
                         h2.append(h_item)
-                if len(h2)<=len(header2[-1]):
+                if len(h2) <= len(header2[-1]):
                     header2.insert(0, h2)
                 else:
-                    header2.insert(0, header[i-1])
+                    header2.insert(0, header[i - 1])
         self._nb_headers = len(header2)
         return header2
 
-
     def __repr__(self):
         return f"<{self.__class__.__name__} shape={self.shape}>"
 
     def __lt__(self, other):
-        if self.page == other.page:
+        if self.region == other.region:
             if self.order < other.order:
                 return True
-        if self.page < other.page:
+        if self.region < other.region:
             return True
 
     @property
     def shape(self):
         if len(self._data) == 0:
             return (0, 0)
         return (len(self.data), len(self._data[0]) if len(self._data[0]) else 0)
@@ -524,39 +544,44 @@
         """
         d = []
         for row in self._data:
             d.append([' '.join([c.Text for c in cell]) for cell in row])
         return d
 
     def to_pandas(self):
-
-        if self.df is None:
-            self.df = pd.DataFrame(self._data)
+        if self.df is not None:
+            return self.df
         else:
+            self.df = Table.to_dataframe(self._data, self._nb_headers)
             return self.df
 
-        if not self.df.empty and len(self.df.index) > 2:
-            if self._nb_headers == 1:
-                headers = self.df.iloc[0]
+    @staticmethod
+    def to_dataframe(data, nb_headers=1):
 
-                self.df = pd.DataFrame(self.df.values[1:], columns=headers)
+        df = pd.DataFrame(data)
+
+        if not df.empty and len(df.index) > 2:
+            if nb_headers == 1:
+                headers = df.iloc[0]
+
+                df = pd.DataFrame(df.values[1:], columns=headers)
             else:
-                tuple_index = [(i, *j) for i, *j in zip(*self._data[0:self._nb_headers])]
+                tuple_index = [(i, *j) for i, *j in zip(*data[0:nb_headers])]
 
                 pd.MultiIndex.from_tuples(tuple_index)
-                self.df = pd.DataFrame(self._data[self._nb_headers:])
+                df = pd.DataFrame(data[nb_headers:])
                 try:
-                    self.df.columns = pd.MultiIndex.from_tuples(tuple_index)
+                    df.columns = pd.MultiIndex.from_tuples(tuple_index)
                 except:
                     pass
 
-        if not self.df.empty:
-            self.df.iloc[:, 0].replace("", np.NaN, inplace=True)
-            self.df.iloc[:, 0].fillna(method='ffill', inplace=True)
-        return self.df
+        if not df.empty:
+            df.iloc[:, 0].replace("", np.NaN, inplace=True)
+            df.iloc[:, 0].fillna(method='ffill', inplace=True)
+        return df
 
     def to_text(self):
         if self.df is not None:
             return self.df.to_string()
         else:
             ""
 
@@ -579,15 +604,15 @@
         For kwargs, check :meth:`pandas.DataFrame.to_excel`.
         Parameters
         ----------
         path : str
             Output filepath.
         """
         kw = {
-            "sheet_name": f"page-{self.page}-table-{self.order}",
+            "sheet_name": f"page-{self.region}-table-{self.order}",
             "encoding": "utf-8",
         }
         kw.update(kwargs)
         writer = pd.ExcelWriter(path)
         self.df.to_excel(writer, **kw)
         writer.save()
 
@@ -628,15 +653,14 @@
     "min_words_horizontal": DEFAULT_MIN_WORDS_HORIZONTAL,
     "intersection_tolerance": 3,
     "intersection_x_tolerance": 3,
     "intersection_y_tolerance": 3,
 }
 
 
-
 class TableFinder(object):
     """
     Given a PDF page, find plausible table structures.
     """
 
     def __init__(self, page, settings={}):
         for k in settings.keys():
@@ -669,15 +693,15 @@
         if by_top is None:
             return []
         #        by_top=[c for c in by_top for t in c if len(t.Text)< 100]
 
         large_clusters = []
         for c in by_top:
 
-            c = [t for t in c if t.Text!='']
+            c = [t for t in c if t.Text != '']
 
             c = [t for t in c if len(t.Text) < 40]
 
             if len(c) >= word_threshold:
                 large_clusters.append(c)
 
         #        large_clusters = list(filter(lambda x: len(x) >= word_threshold, by_top))
@@ -695,35 +719,51 @@
             }
             for r in rects
         ]
 
         return [utils.BoundingBox(**e) for e in edges]
 
     def guess_tables(self):
-        horizontal_lines = [line for line in self.page.horizontal_edges if
-                            line.width < self.page.root_page.content_width * 0.95]
-
 
+        tables = []
         all_tables = self._guess_tables_from_rectangles()
 
+        horizontal_lines = [line for line in self.page.horizontal_edges if
+                            line.width < self.page.root_page.content_width * 0.95]
+
+        #show_rects_and_wait(horizontal_lines, self.page.page_image.copy())
         if len(horizontal_lines) >= 2:
             tables = self._guess_tables_from_lines(horizontal_lines)
             for table in tables:
                 if not utils.is_ovarlaping_with_objects(table, all_tables):
                     all_tables.append(table)
 
-#        show_rects_and_wait(all_tables, self.page.root_page.image.copy())
+#        if tables:
+            #show_rects_and_wait(all_tables, self.page.root_page.page_image.copy())
         tables = self._guess_tables_from_lines(self.guess_table_lines())
         for table in tables:
             if not utils.is_ovarlaping_with_objects(table, all_tables):
                 all_tables.append(table)
 
+        return_tables = []
+        for t in sorted(all_tables, key=lambda x: (x.top, x.left)):
+            if not return_tables:
+                return_tables = [t]
+            found_overlap = False
+            for i in range(0, len(return_tables)):
+                table = return_tables[i]
+                if utils.has_overlap_with_bbox(table, t, allow_touching=True):
+                    table_ = utils.get_BoundingBox_from_objects([t, table])
+                    return_tables[i] = table_
+                    found_overlap = True
+                    break
+            if not found_overlap:
+                return_tables.append(t)
 
-        return [t for t in all_tables if not utils.is_ovarlaping_with_objects(t, self.page.charts)]
-
+        return [t for t in return_tables if not utils.is_ovarlaping_with_objects(t, self.page.charts)]
 
     def snap_edges(self, edges, tolerance=DEFAULT_SNAP_TOLERANCE):
         """
         Given a list of edges, snap any within `tolerance` pixels of one another
         to their positional average.
         """
         v, h = [list(filter(lambda x: x.orientation == o, edges)) for o in ("v", "h")]
@@ -779,14 +819,15 @@
             edge_gen = (
                 self.join_edge_group(items, k[0], join_tolerance) for k, items in edge_groups
             )
             edges = list(itertools.chain(*edge_gen))
         return edges
 
     def _guess_tables_from_rectangles(self, threshold=2):
+        #        show_and_wait()
         rects = [rect for rect in self.page.rects if rect.width > rect.height and rect.height > 2]
         left_right = utils.cluster_objects2(rects, ["left", "right"], rel_tol=0, abs_tol=0.2)
         if left_right is not None:
             left_right = list(filter(lambda x: len(x) >= threshold, left_right))
         if left_right is None:
             return []
 
@@ -802,70 +843,70 @@
                     groups.append(new_group)
                     new_group = [group[i + 1]]
             if new_group:
                 groups.append(new_group)
         return [utils.get_BoundingBox_from_objects(g) for g in groups if len(g) >= threshold]
 
     def _guess_tables_from_lines(self, lines, threshold=3):
-        lines=utils.join_collated_h_edges(lines)
+        lines = utils.join_collated_h_edges(lines)
 
-        min_row_height = 40
-        left_right = utils.cluster_objects2(lines, ["left", "right"], rel_tol=0, abs_tol=5)
+        max_row_height = 40
+        left_right = utils.cluster_objects2(lines, ["left", "right"], abs_tol=10)
 
         if left_right is not None:
-            left_right = list(filter(lambda x: (len(x) >= threshold and x[0].width>20), left_right))
+            left_right = list(filter(lambda x: (len(x) >= threshold and x[0].width > 20), left_right))
         if left_right is None:
             return []
         tables = []
         for group in left_right:
             group = sorted(group, key=lambda x: x.bottom)
             for i in range(0, len(group) - 1):
                 group[i].space_bellow = group[i + 1].bottom - group[i].bottom
-                if i>0:
-                    group[i].space_above = group[i].bottom - group[i-1].bottom
+                if i > 0:
+                    group[i].space_above = group[i].bottom - group[i - 1].bottom
             group[-1].space_bellow = group[-2].space_bellow
             group[0].space_above = group[1].space_above
 
             i = 0
             while i < len(group):
                 line = group[i]
-                if line.space_bellow <= min_row_height:
+                if line.space_bellow <= max_row_height:
                     subgroup = [line]
                 else:
                     subgroup = []
                 i += 1
-                while i < len(group) and np.isclose(line.space_bellow, group[i].space_bellow, atol=min(line.space_above, line.space_bellow)):
-                    if group[i].space_bellow <= min_row_height:
+                while i < len(group) and np.isclose(line.space_bellow, group[i].space_bellow,
+                                                    atol=min(line.space_above, line.space_bellow)):
+                    if group[i].space_bellow <= max_row_height:
                         subgroup.append(group[i])
                     line = group[i]
                     i += 1
-                if i < len(group):
-                    if len(subgroup)>0:
-                        subgroup.append(group[i])
-                    i += 1
+                # if i < len(group):
+                #     if len(subgroup)>0:
+                #         subgroup.append(group[i])
+                #     i += 1
                 if len(subgroup) >= threshold:
-                    bbox=utils.get_BoundingBox_from_objects(subgroup)
-                    txts=utils.get_widthin_BoundingBox(self.page.text_lines, bbox)
-                    if len(txts)>1:
+                    bbox = utils.get_BoundingBox_from_objects(subgroup)
+                    txts = utils.get_widthin_BoundingBox(self.page.text_lines, bbox)
+                    if len(txts) > 1:
                         tables.append(bbox)
 
         return tables
 
     def guess_table_lines(self, token_threshold_v=2, token_threshold_h=2, pruning_cut_off=2):
 
         h_edges = self.words_to_edges_h(word_threshold=token_threshold_h)
-        h_edges=utils.cluster_objects2(h_edges, ["left", "right"], rel_tol=0, abs_tol=5)
+        h_edges = utils.cluster_objects2(h_edges, ["left", "right"], rel_tol=0, abs_tol=5)
         if h_edges is not None:
             h_edges = list(filter(lambda x: len(x) >= token_threshold_v, h_edges))
         if h_edges is not None:
             return [e for g in h_edges for e in g]
         else:
             return []
 
-
     def get_intersections_for_edge(self, edge, intersections):
         intersection_points = []
         for pt, edges in intersections.items():
             edge_v = edges['v'][0]
             edge_h = edges['h'][0]
             if edge == edge_h or edge == edge_v:
                 intersection_points.append(pt)
@@ -945,20 +986,18 @@
         #         "height": r.bottom - r.top,
         #         "justification": "center",
         #         "orientation": "v",
         #     }
         #     for r in rects
         # ]
 
-        rects= [utils.BoundingBox(**e) for e in edges]
-
+        rects = [utils.BoundingBox(**e) for e in edges]
 
         return rects
 
-
     def edges_to_intersections(self, edges, x_tolerance=1, y_tolerance=1):
         """
         Given a list of edges, return the points at which they intersect
         within `tolerance` pixels.
         """
         intersections = {}
         v_edges, h_edges = [
@@ -1115,48 +1154,232 @@
             edges = self.merge_edges(
                 edges,
                 snap_tolerance=settings["snap_tolerance"],
                 join_tolerance=settings["join_tolerance"],
             )
         return utils.filter_edges(edges, min_length=settings["edge_min_length"])
 
+
 def guess_table_from_token_lines(region, token_lines, has_table=None):
-        if len(token_lines) < 3:
-            return None
+    if len(token_lines) < 3:
+        return None
 
-        guess_nb_cols_most_common = Counter(len(l) for l in token_lines).most_common(1)
+    guess_nb_cols_most_common = Counter(len(l) for l in token_lines).most_common(1)
 
-        if guess_nb_cols_most_common[0][1]<3:
-            return False
+    if guess_nb_cols_most_common[0][1] < 3:
+        return False
 
-        else:
-            guess_nb_cols=guess_nb_cols_most_common[0][0]
+    else:
+        guess_nb_cols = guess_nb_cols_most_common[0][0]
 
-        if guess_nb_cols<3:
-            return False
+    if guess_nb_cols < 3:
+        return False
+
+    table_lines = []
+    rows_added = False
+    for l in token_lines:
+        if guess_nb_cols + 1 >= len(l) >= guess_nb_cols - 1:
+            table_lines.append(l)
+            rows_added = True
+        elif rows_added:
+            break
+    if len(table_lines) >= 3:
+        first_row = table_lines[0]
+        for t in range(0, len(first_row) - 1):
+            h = (first_row[t + 1].left + first_row[t].right) / 2
+            for row in table_lines[1:]:
+                if t >= len(row) - 1:
+                    continue
+                if (h > row[t].right and h < row[t + 1].left) or row[t + 1].right < h:
+                    continue
+                else:
+                    return None
+
+        table = Table(region, textlines=table_lines, rect=utils.get_BoundingBox_from_objects(has_table),
+                      paragraph=token_lines).extract()
+        #            print(table.to_pandas().to_string())
+        return table
+    return None
 
-        table_lines = []
-        rows_added=False
-        for l in token_lines:
-            if guess_nb_cols + 1 >= len(l) >= guess_nb_cols - 1:
-                table_lines.append(l)
-                rows_added=True
-            elif rows_added:
-                break
-        if len(table_lines) >= 3:
-            first_row = table_lines[0]
-            for t in range(0, len(first_row) - 1):
-                h = (first_row[t + 1].left +first_row[t].right) / 2
-                for row in table_lines[1:]:
-                    if t>=len(row)-1:
-                        continue
-                    if (h > row[t].right and h < row[t + 1].left) or row[t + 1].right<h:
-                        continue
-                    else:
-                        return None
 
-            table = Table(region, textlines=table_lines,rect = utils.get_BoundingBox_from_objects(has_table), paragraph = token_lines).extract()
-#            print(table.to_pandas().to_string())
-            return table
+def guess_tables_from_lines(lines, threshold=3):
+    lines = utils.join_collated_h_edges(lines)
+
+    left_right = utils.cluster_objects2(lines, ["left", "right"], abs_tol=10)
+
+    if left_right is not None:
+        left_right = list(filter(lambda x: (len(x) >= threshold and x[0].width > 20), left_right))
+    if left_right is None:
+        return []
+    tables = []
+    for group in left_right:
+        group = sorted(group, key=lambda x: x.bottom)
+        for i in range(0, len(group) - 1):
+            group[i].space_bellow = group[i + 1].bottom - group[i].bottom
+            if i > 0:
+                group[i].space_above = group[i].bottom - group[i - 1].bottom
+        group[-1].space_bellow = group[-2].space_bellow
+        group[0].space_above = group[1].space_above
+
+        i = 0
+
+        group_bot = utils.cluster_objects(group, "space_bellow", tolerance=5)
+
+    return tables
+
+
+def does_it_intersect(x, xmin, xmax):
+    return (x <= xmax and x >= xmin)
+
+
+def find_bounding_rectangle(x, y, h_lines, v_lines):
+    """
+    Given a collection of lines, and a point, try to find the rectangle
+    made from the lines that bounds the point. If the point is not
+    bounded, return None.
+    """
+
+    v_intersects = [l for l in v_lines
+                    if does_it_intersect(y, l.top, l.bottom)]
+
+    h_intersects = [l for l in h_lines
+                    if does_it_intersect(x, l.left, l.right)]
+
+    if len(v_intersects) < 2 or len(h_intersects) < 2:
         return None
 
+    v_left = [v.left for v in v_intersects
+              if v.left < x]
+
+    if len(v_left) == 0:
+        v_left = [v.left for v in h_intersects
+                  if v.left < x]
+
+    v_right = [v.left for v in v_intersects
+               if v.left > x]
+
+    if len(v_right) == 0:
+        v_right = [v.right for v in h_intersects
+                   if v.right > x]
+
+    if len(v_left) == 0 or len(v_right) == 0:
+        return None
+
+    x0, x1 = max(v_left), min(v_right)
+
+    h_down = [h.top for h in h_intersects
+              if h.top < y]
+    if len(h_down) == 0:
+        h_down = [h.bottom for h in v_intersects
+                  if h.bottom > y]
+
+    h_up = [h.top for h in h_intersects
+            if h.top > y]
+
+    if len(h_up) == 0:
+        h_up = [h.top for h in v_intersects
+                if h.top > y]
+
+    if len(h_down) == 0 or len(h_up) == 0:
+        return None
+
+    y0, y1 = max(h_down), min(h_up)
+
+    return (x0, y0, x1, y1)
+
+
+from collections import defaultdict
+import math
+
+
+def map_tokens(tokens, h_lines, v_lines):
+    box_token_dict = {}
+
+    for token in tokens:
+        # choose the bounding box that occurs the majority of times for each of these:
+        bboxes = defaultdict(int)
+        l_x, l_y = token.left, token.top
+        bbox_l = find_bounding_rectangle(l_x, l_y, h_lines, v_lines)
+        bboxes[bbox_l] += 1
+
+        c_x, c_y = math.floor((token.left + token.right) / 2), math.floor((token.top + token.bottom) / 2)
+        bbox_c = find_bounding_rectangle(c_x, c_y, h_lines, v_lines)
+        bboxes[bbox_c] += 1
+
+        u_x, u_y = token.top, token.bottom
+        bbox_u = find_bounding_rectangle(u_x, u_y, h_lines, v_lines)
+        bboxes[bbox_u] += 1
+
+        # if all values are in different boxes, default to character center.
+        # otherwise choose the majority.
+        if max(bboxes.values()) == 1:
+            bbox = bbox_c
+        else:
+            bbox = max(bboxes.items(), key=lambda x: x[1])[0]
+
+        if bbox is None:
+            continue
+
+        if bbox in box_token_dict.keys():
+            box_token_dict[bbox].append(token)
+            continue
+
+        box_token_dict[bbox] = [token]
+
+    return box_token_dict
+
+
+def boxes_to_table(box_record_dict):
+    """
+    Converts a dictionary of cell:characters mapping into a python list
+    of lists of strings. Tries to split cells into rows, then for each row
+    breaks it down into columns.
+    """
+    boxes = box_record_dict.keys()
+    rows = sorted(list(set(b[1] for b in boxes)), reverse=True)
+    table = []
+    if len(rows) < 2:
+        return table
+    for row in sorted(rows):
+        sorted_row = sorted([b for b in boxes if b[1] == row], key=lambda b: b[0])
+        table.append([box_record_dict[b] for b in sorted_row])
+
+    return sanitise_table(table)
+
+
+def sanitise_table(table):
+    if len(table) < 3:
+        return []
+
+    guess_nb_cols_most_common = Counter(len(l) for l in table if len(l) > 1).most_common(1)
+
+    if not guess_nb_cols_most_common:
+        return []
+    if guess_nb_cols_most_common[0][1] < 2:
+        return []
+
+    else:
+        guess_nb_cols = guess_nb_cols_most_common[0][0]
+
+    if guess_nb_cols < 2:
+        return []
+
+    # only a subset of columns in a pragraph form a table
+    rows = []
+
+    rows_idx = [i for i, r in enumerate(table) if max(guess_nb_cols - 2, 2) <= len(r) <= guess_nb_cols + 1]
+
+    table = table[min(rows_idx):max(rows_idx) + 1]
+
+    return table
+
+
+def tokens_to_string(tokens):
+    text = ' '.join([t.Text for t in tokens])
+    return text
+
 
+def extract_table_from_rects(region):
+    table = boxes_to_table(map_tokens(region.tokens, region.horizontal_edges, region.vertical_edges))
+    return table
+    # if table!=[]:
+    #     return Table.to_dataframe(table)
```

## pdf2txt/table_ml.py

```diff
@@ -9,15 +9,15 @@
 
 
 
 dist_thresh=24
 min_size=2
 
 
-def extract_table(text_lines, debug=False):
+def extract_table(text_lines, debug=True):
     text_coordinates = []
     raw_text = []
 
 
     for line in text_lines:
         for token in line:
             text_coordinates.append((token.left, token.top, token.right, token.bottom))
@@ -217,17 +217,17 @@
         i=col_index(rows, item, last_i)
         j=col_index(columns, item, last_j)
         if i is None or j is None:
             continue
         if i>= len(m):
             m[i]=defaultlist()
         if len(m[i]) > j:
-            m[i][j]+=' '+item.Text
+            m[i][j]+=' '+str(item.Text)
         else:
-            m[i][j] = item.Text
+            m[i][j] = str(item.Text)
 #        print(i, j, item.Text)
 
     return m
 
 def get_column_for_item(columns, item):
     for i, column in enumerate(columns):
         if item in column:
@@ -236,10 +236,10 @@
 
 
 class defaultlist(list):
 
    def __setitem__(self, index, value):
       size = len(self)
       if index >= size:
-         self.extend(0 for _ in range(size, index + 1))
+         self.extend('' for _ in range(size, index + 1))
 
       list.__setitem__(self, index, value)
```

## pdf2txt/utils.py

```diff
@@ -6,21 +6,22 @@
 from pdfminer.layout import LAParams
 from pdfminer.pdfparser import PDFParser
 from pdfminer.pdfpage import PDFPage
 from pdfminer.psparser import PSLiteral
 from pdfminer.pdfdocument import PDFDocument
 from math import floor, isclose
 from kdmt.geometry import rectangle_a_inside_b
-
+from kdmt.strings import commonOverlapIndexOf
 from operator import itemgetter
 from statistics import mean
 import itertools
 from pdf2txt.settings import DEFAULT_MIN_WORDS_VERTICAL, DEFAULT_X_TOLERANCE, DEFAULT_Y_TOLERANCE
 from copy import copy
-import ast
+import ast, re
+
 import tempfile, shutil
 import numpy as np
 import pdf2image
 import cv2
 
 
 class BoundingBox():
@@ -431,19 +432,21 @@
 
 
 def has_overlap_with_bbox(a, b, allow_touching=False):
     if isinstance(a, tuple):
         a = BoundingBox(a[0], a[1], a[2], a[3])
     if isinstance(b, tuple):
         b = BoundingBox(b[0], b[1], b[2], b[3])
-    if allow_touching:
-        return not (round(a.right, 2) <= round(b.left, 2) or round(a.left, 2) >= round(b.right, 2) or round(a.bottom,
-                                                                                                            2) <= round(
-            b.top, 2) or round(a.top, 2) >= round(b.bottom, 2))
-    return not (a.right < b.left or a.left > b.right or a.bottom < b.top or a.top > b.bottom)
+
+    overlaping=not (a.right < b.left or a.left > b.right or a.bottom < b.top or a.top > b.bottom)
+
+    if allow_touching and not overlaping:
+        return (round(a.right) == round(b.left) or round(a.left) == round(b.right) or round(a.bottom) == round(
+            b.top) or round(a.top) == round(b.bottom))
+    return overlaping
 
 
 def is_touching_with_bbox(line, bbox, tolerance=1):
     if isinstance(line, tuple):
         line = BoundingBox(line[0], line[1], line[2], line[3])
     if isinstance(bbox, tuple):
         bbox = BoundingBox(bbox[0], bbox[1], bbox[2], bbox[3])
@@ -1060,22 +1063,22 @@
 
     edges['v'] = [e for e in edges['v'] if e['axis'] not in intersections]
     edges['h'] = [e for e in edges['h'] if e['axis'] not in intersections]
 
     return edges
 
 
-def get_fonts_statistics(tokens):
-    if len(tokens) == 0:
+def get_fonts_statistics(text_lines):
+    if len(text_lines) == 0:
         return {}
 
-    if "font" in tokens:
+    if "font" in text_lines:
         print("font")
-    sizes = [word.font_size for token in tokens for word in token.original_words]
-    font_names = [word.font_name for token in tokens for word in token.original_words]
+    sizes = [tl[0].font_size for tl in text_lines]
+    font_names = [tl[0].font_name for tl in text_lines]
 #    interlines = [int(i[0].top - j[0].bottom) for i, j in zip(tokens[1:], tokens[:-1])]
     #    ncolors = [word.font_ncolor for line in texlines for token in line for word in token.original_words]
     font_sizes_by_frequency = sorted(set(sizes), key=lambda ele: -sizes.count(ele))
     font_names_by_frequency = sorted(set(font_names), key=lambda ele: -sizes.count(ele))
 
     return {
         'most_frequent': max(set(sizes), key=sizes.count),
@@ -1103,18 +1106,18 @@
             next_token = tokens[i + 1]
 
         line = [token]
 
         while next_token and are_in_same_line2(token, next_token):
             line.append(next_token)
             line = sorted(line, key=lambda elem: elem.left)
-            char_space=next_token.original_words[0].font_size/2
+            char_space=next_token.original_words[0].font_width
             if line[-1].left-line[-2].right<char_space:
                 line[-2].combine(line[-1])
-                del tokens[i+1]
+                tokens.remove(line[-1])
                 del line[-1]
                 next_token=line[-1]
                 i-=1
 
 
 
             i += 1
@@ -1127,14 +1130,29 @@
         line = sorted(line, key=lambda elem: elem.left)
         lines.append(line)
         i += 1
 
     return lines
 
 
+def _fix_lines(text_lines):
+    index_to_remove=[]
+    last=text_lines[0]
+
+    for tl in enumerate(text_lines):
+        if len(tl)<=1:
+            continue
+        for token in tl:
+            if tl.left<last.right:
+                common_idx=commonOverlapIndexOf(last["value"], tl["value"])
+
+                continue
+        last=tl
+
+
 def find_clusters_1d(vals, dist_thresh):
     """
     Very simple clusting in 1D: Sort <vals> and calculate distance between values. Form clusters when <dist_thresh> is
     exceeded.
 
     Returns a list of clusters, where each element in the list is a np.array with indices of <vals>.
     """
@@ -1162,10 +1180,17 @@
         clusters.append(np.array(cur_clust))
 
     assert len(vals) == sum(map(len, clusters))
 
     return clusters
 
 
+def join_lines(text):
+    text = re.sub("(?<!\n)\n(?!\n)", " ", text)  # Remplacer les sauts de ligne uniques par des espaces
+    text = re.sub("- ", "", text)  # Supprimer les tirets en fin de ligne
+    text = re.sub(" +", " ", text)  # Remplacer les espaces multiples par un seul espace
+    return text
+
+
 if __name__ == "__main__":
     print(get_type("0,5 % "))
     print(get_type("-"))
```

## pdf2txt/version.py

```diff
@@ -1 +1 @@
-__version__="0.7.1"
+__version__="0.7.11"
```

## pdf2txt/core/component.py

```diff
@@ -1,97 +1,42 @@
 from itertools import chain
 from pdf2txt import  utils
-
+from pdf2txt.settings import DEFAULT_X_TOLERANCE, DEFAULT_Y_TOLERANCE
 
 
 
 class Component(object):
     cached_properties = ["_rect_edges", "_edges", "_objects"]
     objects=None
     _horizontal_lines=None
     _vertical_lines=None
-    image=None
-
     def flush_cache(self, properties=None):
         props = self.cached_properties if properties is None else properties
         for p in props:
             if hasattr(self, p):
                 delattr(self, p)
 
     @property
     def rects(self):
         _rects=[utils.BoundingBox(**rect) for rect in self.objects.get("rect", []) if rect["height"]>0 and rect["width"]>0]#+[c for c in self.curves if c.width<100 and c.height<100]
 
-        return list(set([r for r in _rects if r.width/r.height >0.01 and r.height/r.width>0.01]))
+        return [r for r in _rects if r.width/r.height >0.01 and r.height/r.width>0.01]
 
     @property
     def lines(self):
         if hasattr(self, "__lines"):
             return self.__lines
 
         h_lines=[rect for rect in self.rects+self.curves if rect.height<1 and rect.width>10]+[utils.BoundingBox(**line) for line in self.objects.get("line", []) if line["width"]>line["height"]]
         v_lines=[rect for rect in self.rects+self.curves if rect.width<1 and rect.height>10]+[utils.BoundingBox(**line) for line in self.objects.get("line", []) if line["width"]<line["height"]]
 
 
         h_lines=utils.join_collated_h_edges(h_lines)
         v_lines=utils.join_collated_v_edges(v_lines)
 
-        # _lines=[]
-        # aggregated=[]
-        # if h_lines is not None:
-        #     for h in h_lines:
-        #         h=sorted(h, key=lambda x: x.left)
-        #         if len(h)==1:
-        #             _lines.append(h[0])
-        #         for i in range(0, len(h)-1):
-        #             if utils.has_overlap_with_bbox(h[i], h[i+1]):
-        #                 aggregated.append(h[i])
-        #             elif aggregated!=[]:
-        #                 aggregated_line = utils.get_BoundingBox_from_objects(aggregated)
-        #                 setattr(aggregated_line, "width", aggregated_line.right - aggregated_line.left)
-        #                 setattr(aggregated_line, "height", aggregated_line.bottom - aggregated_line.top)
-        #
-        #                 _lines.append(aggregated_line)
-        #                 aggregated=[]
-        #             else:
-        #                 _lines.append(h[i])
-        #         if aggregated!=[]:
-        #             aggregated.append(h[i+1])
-        #             aggregated_line=utils.get_BoundingBox_from_objects(aggregated)
-        #             setattr(aggregated_line, "width", aggregated_line.right-aggregated_line.left)
-        #             setattr(aggregated_line, "height", aggregated_line.bottom-aggregated_line.top)
-        #
-        #             _lines.append(aggregated_line)
-        #             aggregated=[]
-        # aggregated=[]
-        # if v_lines is not None:
-        #     for h in v_lines:
-        #         h=sorted(h, key=lambda x: x.top)
-        #         if len(h)==1:
-        #             _lines.append(h[0])
-        #         for i in range(0, len(h)-1):
-        #             if utils.has_overlap_with_bbox(h[i], h[i+1]):
-        #                 aggregated.append(h[i])
-        #             elif aggregated!=[]:
-        #                 aggregated_line = utils.get_BoundingBox_from_objects(aggregated)
-        #                 setattr(aggregated_line, "width", aggregated_line.right - aggregated_line.left)
-        #                 setattr(aggregated_line, "height", aggregated_line.bottom - aggregated_line.top)
-        #
-        #                 _lines.append(aggregated_line)
-        #                 aggregated=[]
-        #             else:
-        #                 _lines.append(h[i])
-        #         if aggregated!=[]:
-        #             aggregated.append(h[i+1])
-        #             aggregated_line=utils.get_BoundingBox_from_objects(aggregated)
-        #             setattr(aggregated_line, "width", aggregated_line.right-aggregated_line.left)
-        #             setattr(aggregated_line, "height", aggregated_line.bottom-aggregated_line.top)
-        #
-        #             _lines.append(aggregated_line)
-        #             aggregated=[]
 
 
         self.__lines=h_lines+v_lines
         return self.__lines
 
     def get_non_text_objects(self):
         return self.lines+self.rects+self.curves
@@ -113,23 +58,22 @@
             elif c["text"]=="":
                 c["text"]="'"
         return chars_
 
     @property
     def horizontal_lines(self):
         if self._horizontal_lines is None:
-            self._horizontal_lines=[line for line in self.lines if line.height<=1 and line.width>10]
+            self._horizontal_lines=[line for line in self.lines if line.height<1 and line.width>10]
             return self._horizontal_lines
         return self._horizontal_lines
 
-
     @property
     def vertical_lines(self):
         if self._vertical_lines is None:
-            self._vertical_lines=[line for line in self.lines if line.width<=1 and line.height>10]
+            self._vertical_lines=[line for line in self.lines if line.width<1 and line.height>10]
             return self._vertical_lines
         return self._vertical_lines
 
 
     @property
     def rect_edges(self):
         if hasattr(self, "_rect_edges"):
```

## pdf2txt/core/document.py

```diff
@@ -1,11 +1,11 @@
 from pdf2txt.core import Component
 from .page import Page
 import pytesseract
-from poppdf import PdfDocument
+from poppdf import poppler
 import pathlib
 import os
 from pdfminer.pdfparser import PDFParser
 from pdfminer.pdfdocument import PDFDocument
 from pdfminer.pdfpage import PDFPage
 from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
 from pdfminer.layout import LAParams
@@ -15,88 +15,121 @@
 import regex as re
 from pdf2txt.utils import extract_text, TemporaryDirectory, get_page_layout
 from pdf2txt.utils import convert_pdf_to_image
 from collections import defaultdict
 from pdf2txt.core.filtering import TokenList
 from  collections import Counter
 
-class Document(PdfDocument):
+
+
+class Document(Component):
     cached_properties = Component.cached_properties + ["_pages"]
 
-    def __init__(self, stream, path, first_page=None, last_page=None, laparams=None, password=None):
-        super().__init__(path, first_page=first_page, last_page=last_page, userpw=password)
+    def __init__(self, stream, path, pages=None, laparams=None, password="", fix_with_ocr=False):
         self.laparams = None if laparams is None else LAParams(**laparams)
         self.stream = stream
-
+        self.pages_to_parse = pages
         self._pdf_file_path=path
         rsrcmgr = PDFResourceManager()
-        self.doc = PDFDocument(PDFParser(stream))
-
-        self._pdf_file_path=path
+        self.doc = PDFDocument(PDFParser(stream), password=password)
         self.metadata = {}
-        self.paragraphs=Paragraphs(self)
+        self._paragraphs=Paragraphs(self)
+        self.fix_with_ocr=fix_with_ocr
         self._token_list = []
-
+        self._element_indexes_by_font = defaultdict(set)
+        for info in self.doc.info:
+            self.metadata.update(info)
+        for k, v in self.metadata.items():
+            if hasattr(v, "resolve"):
+                v = v.resolve()
+            if type(v) == list:
+                self.metadata[k] = list(v)
+            elif isinstance(v, PSLiteral):
+                self.metadata[k] = v.name
+            elif isinstance(v, bool):
+                self.metadata[k] = v
+            else:
+                self.metadata[k] = v
         self.device = PDFPageAggregator(rsrcmgr, laparams=self.laparams)
         self.interpreter = PDFPageInterpreter(rsrcmgr, self.device)
 
+
     @classmethod
     def open(cls, path_or_fp, **kwargs):
         if isinstance(path_or_fp, (str, pathlib.Path)):
             return cls(open(path_or_fp, "rb"),path_or_fp, **kwargs)
         else:
             return cls(path_or_fp, path_or_fp, **kwargs)
 
+    def get_page(self, page):
+        try:
+            self.interpreter.process_page(page)
+        except:
+            return None
+        return self.device.get_result()
 
     @property
     def pages(self):
         if hasattr(self, "_pages"):
             return self._pages
 
+
+        pp = self.pages_to_parse
         self._pages = []
         for i, page in enumerate(PDFPage.create_pages(self.doc)):
             page_number = i
+            if pp is not None and page_number not in pp:
+                continue
 
-            p = Page(self, self.pdf_pages[i], page, page_number=page_number)
-
-            p.set_page_layout()
-            self._pages.append(p)
-        return self._pages
 
+            page_image = poppler.image_from_path(pdf_path=self._pdf_file_path, first_page=page_number+1, last_page=page_number+1,dpi=500)[0]
+            p = Page(self, page, page_number=page_number, page_image=page_image,fix_with_ocr=self.fix_with_ocr)
 
 
+            self._pages.append(p)
 
-    def get_page(self, page):
-        try:
-            self.interpreter.process_page(page)
-        except:
-            return None
-        return self.device.get_result()
+        return self._pages
 
+    # @property
+    # def tokens(self):
+    #     return [token for page in self.pages for token in page.tokens]
 
     def close(self):
         self.stream.close()
 
     def __enter__(self):
         return self
 
     def __exit__(self, type, value, traceback):
         self.flush_cache()
         self.close()
 
     @property
+    def objects(self):
+        if hasattr(self, "_objects"):
+            return self._objects
+        all_objects = {}
+        for p in self.pages:
+            for kind in p.objects.keys():
+                all_objects[kind] = all_objects.get(kind, []) + p.objects[kind]
+        self._objects = all_objects
+        return self._objects
+
+    @property
     def Title(self):
         largest_fonts=None
-        candidates=[token[0] .Text for p in self.pdf_pages for token in p.title]
+        candidates=sorted([token[0] for p in self.pages for token in p.title], key=lambda x: -x.font_size)
+        candidates=[c.Text for c in candidates]
+
         if candidates!=[]:
             most_common=Counter(candidates).most_common(1)[0]
             if most_common[1]>1:
                 return most_common[0]
             else:
-                candidates = [t[0] for p in self.pdf_pages for t in p.title]
+                candidates = [t[0] for p in self.pages for t in p.title]
                 max_size=max([c.font_size for c in candidates])
                 largest_fonts = [x.Text for x in candidates if x.font_size == max_size]
 
         if largest_fonts is not None:
             return ' '.join(largest_fonts)
 
     @property
@@ -105,21 +138,24 @@
         A TokenList containing all tokens in the document.
 
         Returns:
             TokenList: All tokens in the document.
         """
         return TokenList(self)
 
+    @property
+    def paragraphs(self):
+        return self._paragraphs.paragraphs
+
     def pretty_print(self):
-        for p in self.paragraphs.paragraphs:
+        for p in self.paragraphs:
             print(p.Text)
     @property
     def Text(self):
-        return '\n'.join([p.text for p in self.pdf_pages])
-#        return '\n'.join([p.Text for p in self.paragraphs.paragraphs])
+        return '\n'.join([p.Text for p in self._paragraphs.paragraphs])
 
     def get_text_matches_regex(self, regex_str, case_sensitive=True):
         """
         Filter for tokens whose text contains the given string.
 
         Args:
             text (str): The text to filter for.
```

## pdf2txt/core/indexer.py

```diff
@@ -7,15 +7,15 @@
 
     print("\nBUILDING INDEX\n...")
 
     inv_index = []
 
     # Preprocesses and indexes collection per document.
 
-    for paragraph in pdf_document.paragraphs.paragraphs:
+    for paragraph in pdf_document._paragraphs._paragraphs:
         docnumber = paragraph.number
 
         text = paragraph.Text
 
         text.replace('\n', '')
         tokenizedline = re.split('[\W]', text)
```

## pdf2txt/core/page.py

```diff
@@ -3,361 +3,506 @@
 from pandas import DataFrame
 
 from pdf2txt import utils
 from pdf2txt.core import Component
 from pdf2txt.core.paragraph import ContentType
 from pdf2txt.core.paragraph import extract
 from pdf2txt.core.token import Token, TokenExtractor
-from pdf2txt.core.word import Word
+from pdf2txt.core.word import WordExtractor, Word
 from pdf2txt.doc_analyzer.image_analyzer import PageAnalyzer
 from pdf2txt.charts import extract_charts
 from pdf2txt.settings import ALL_ATTRS
 from pdf2txt.settings import DEFAULT_WORD_EXTRACTION_SETTINGS, DEFAULT_TOKEN_EXTRACTION_SETTINGS
-from pdf2txt.table import TableFinder#, Table
-from pdf2txt.table import Table
+from pdf2txt.table import TableFinder, extract_table_from_rects  # , Table
+from pdf2txt.table import Table, guess_tables_from_lines
 from pdf2txt.utils import BoundingBox
+from pdf2txt.core.paragraph import guess_titles
+from pdf2txt.charts import Chart
 from pdf2txt.utils import resolve_all
-from pdf2txt.doc_analyzer.img import show_rects_and_wait
+from pdf2txt.doc_analyzer.img import show_rects_and_wait, show_and_wait
 import cv2
-
+from math import isclose
+from poppdf.pdf import xml_ocr_from_image
 import numpy as np
-
+from kdmt.geometry import rectangle_intersect
 
 lt_pat = re.compile(r"^LT")
 
-
+PAGE_HEIGHT = 1260
+PAGE_WIDTH = 890
 
 
 class Page(Component):
     cached_properties = Component.cached_properties + ["_layout"]
     is_original = True
-    __text_lines=None
+    _text_lines = None
 
-    def __init__(self, parent, page_pdf, page_obj, page_number=None, bbox=None, debug=True):
+    def __init__(self, parent, page_obj, page_number=None, page_image=None, bbox=None, fix_with_ocr=False):
         self.document = parent
         self.page_obj = page_obj
         self.page_number = page_number
-        self.title=[]
-        self._words=None
-        self.token_start=None
-        self.token_end=None
-        self.image=cv2.cvtColor(np.asarray(page_pdf.page_image), code=cv2.COLOR_RGB2BGR)
-
-
-        self._page_pdf=page_pdf
-        if self._page_pdf is not None:
-            self._region_extractor=PageAnalyzer(self._page_pdf)
-
-        if bbox is None:
-            self.bbox = BoundingBox(**page_pdf.bbox)
-
-        self.table_finder=TableFinder(self)
-        self.root_page=self
-        self._left_margin=None
-        self._right_margin=None
-        self._top_margin=None
-        self._bottom_margin=None
+        self.title = []
+        self._words = None
+        self.token_start = None
+        self.token_end = None
 
+        self.page_image = page_image
+        #        self._tokens=None
 
-    def detect_semantic_structure(self, debug=True):
- #       show_rects_and_wait(self.charts, self.image, "charts", color=(0, 255, 0))
+        mediabox = page_obj.attrs.get("MediaBox")
 
-        self.regions.sort(key=lambda re: ( re.left, re.top))
+        self.mediabox = resolve_all(mediabox)
+        m = self.mediabox
 
-        paragraph_number=0
-        font_body={}
-        page_font_statistics=self.font_statistics
+        if bbox is None:
+            self.bbox = BoundingBox(
+                min(m[0], m[2]),
+                min(m[1], m[3]),
+                max(m[0], m[2]),
+                max(m[1], m[3]),
+            )
+        self._left_margin = None
+        self._right_margin = None
+        self._top_margin = None
+        self._bottom_margin = None
+        size = (PAGE_WIDTH, PAGE_HEIGHT)
+        # high resolution image foe OCR
+
+        if not isinstance(self, Region):
+            self.alto = None
+            if fix_with_ocr:
+                self.alto = xml_ocr_from_image(self.page_image, size=size, options='--psm 3', thresholding='simple')
+
+            self.page_image = cv2.cvtColor(np.asarray(self.page_image), code=cv2.COLOR_RGB2BGR)
+            # reduce image size for region analysis
+            self.page_image = cv2.resize(self.page_image, size, interpolation=cv2.INTER_AREA)
+            self.set_page_layout()
+
+            # used to extract regions
+            nb_regions = len(self.regions)
+        self.table_finder = TableFinder(self)
+        self.root_page = self
+
+    def detect_semantic_structure_bk(self, debug=True):
+
+        self.regions.sort(key=lambda re: (re.left, re.top))
+
+        paragraph_number = 0
+        font_body = {}
+        page_font_statistics = self.font_statistics
         for region_number, region in enumerate(self.regions):
             font_statistics = region.font_statistics
-            if self.page_number==0 and region_number <=1:
-                if region_number==0:
+            if self.page_number == 0 and region_number <= 1:
+                if region_number == 0:
+                    self.find_header(region, region_number == 1)
+                elif region_number == 1 and region.height < self.bbox.height / 8:
                     self.find_header(region, region_number == 1)
-                elif region_number==1 and region.height<self.bbox.height/8:
-                    self.find_header(region, region_number==1)
-            elif self.page_number>0 and region_number==0 and region.height<self.bbox.height/8:
+            elif self.page_number > 0 and region_number == 0 and region.height < self.bbox.height / 8:
                 self.find_header(region, region_number == 1)
 
-            title_font={}
-            paragraphs=[]
-            if len(region.text_lines)>0:
+            title_font = {}
+            paragraphs = []
+            if len(region.text_lines) > 0:
                 paragraphs = self.extract_paragraph(region)
             for p in paragraphs:
-                check_title=True
-                paragraph_number+=1
-                paragraph = self.document.paragraphs.get_last_paragraph()
+                check_title = True
+                paragraph_number += 1
+                paragraph = self.document._paragraphs.get_last_paragraph()
 
                 for n, tl in enumerate(p):
                     if isinstance(tl, Table) or isinstance(tl, DataFrame):
-                        if paragraph is not None and len(paragraph.content)>0:
-                            t=paragraph.content[-1]["content"]
-                            if not isinstance(t, DataFrame) and check_title and t is not None and self.is_title2(t, font_statistics,
-                                                                                page_font_statistics, title_font={}):
+                        if paragraph is not None and len(paragraph.content) > 0:
+                            t = paragraph.content[-1]["content"]
+                            if not isinstance(t, DataFrame) and check_title and t is not None and self.is_title2(t,
+                                                                                                                 font_statistics,
+                                                                                                                 page_font_statistics,
+                                                                                                                 title_font={}):
                                 del paragraph.content[-1]
-                                paragraph = self.document.paragraphs.create_paragraph()
+                                paragraph = self.document._paragraphs.create_paragraph()
                                 paragraph.title = t
                                 check_title = False
                             else:
                                 if isinstance(tl, Table):
                                     columns = tl.to_pandas().columns.tolist()
-                                else:#Dataframe
+                                else:  # Dataframe
                                     columns = tl.columns.tolist()
-                                if len(columns)>0:
+                                if len(columns) > 0:
 
-                                    if paragraph is not None and len(paragraph.content)>0 and len(columns)>0:
-                                        first=columns[0]
-                                        t=self.get_token_with_value(first)
-                                        if check_title and t is not None and self.is_title2([t], page_font_statistics, page_font_statistics,title_font):
-                                            paragraph = self.document.paragraphs.create_paragraph()
+                                    if paragraph is not None and len(paragraph.content) > 0 and len(columns) > 0:
+                                        first = columns[0]
+                                        t = self.get_token_with_value(first)
+                                        if check_title and t is not None and self.is_title2([t], page_font_statistics,
+                                                                                            page_font_statistics,
+                                                                                            title_font):
+                                            paragraph = self.document._paragraphs.create_paragraph()
                                             paragraph.title = [t]
                                         if paragraph is None:
-                                            paragraph = self.document.paragraphs.create_paragraph()
+                                            paragraph = self.document._paragraphs.create_paragraph()
                         elif paragraph is None:
-                            paragraph = self.document.paragraphs.create_paragraph()
+                            paragraph = self.document._paragraphs.create_paragraph()
                         paragraph.add_content(tl, ContentType.Table)
 
-                    elif check_title and (paragraph is None or self.is_title2(tl, font_statistics, page_font_statistics,title_font, font_body)):
-#                        existing_title=self.document.paragraphs.filter_by_title_equal(tl)
-                        paragraph=self.document.paragraphs.create_paragraph()
-                        paragraph.title=tl
+                    elif check_title and (
+                            paragraph is None or self.is_title2(tl, font_statistics, page_font_statistics, title_font,
+                                                                font_body)):
+                        #                        existing_title=self.document._paragraphs.filter_by_title_equal(tl)
+                        paragraph = self.document._paragraphs.create_paragraph()
+                        paragraph.title = tl
                         title_font['name'] = tl[0].font + str(tl[0].Text.isupper() or tl[0].is_bold)
                         title_font['size'] = tl[0].font_size
-                        check_title=False
+                        check_title = False
                     else:
                         paragraph.add_content(tl, ContentType.Text)
-                        if tl[0].font_size<=self.font_statistics['average']:
-                            font_body['name']= tl[0].font+str(tl[0].is_bold)
+                        if tl[0].font_size <= self.font_statistics['average']:
+                            font_body['name'] = tl[0].font + str(tl[0].is_bold)
                             font_body['size'] = tl[0].font_size
 
-                        check_title=True
+                        check_title = True
 
-    def extract_paragraph(self, region):
-        returned_paragraphs= []
+    def detect_semantic_structure(self, debug=False):
+        text_lines = []
+        for region in self.regions:
+            text_lines.extend(region.text_lines)
 
-        g_paragraph=self.extract_paragaph_from_graph(region)
+        titles=guess_titles(text_lines, self.font_statistics)
+        title_font={}
 
-        if g_paragraph:
-            returned_paragraphs=g_paragraph
-        else:
-            txt_paragraphs = extract(region.text_lines)
+        if debug:
+            show_rects_and_wait(self.regions, self.page_image.copy())
 
-            for p in txt_paragraphs:
-                paragraph = []
-                table_region=None
-                text_lines = Table.extract_table_lines_from_paragaraph(p)
-                table_regions = utils.get_partially_overlapping_objects(
-                    utils.get_BoundingBox_from_objects([t for l in p for t in l]), region.tables)
-                # if table_regions:
-                #     table_region=utils.get_BoundingBox_from_objects(table_regions)
-                #
-#                show_rects_and_wait(region.parent_page.tables, self.image.copy())
-                table=None
-                i = 0
-                if table_regions:
-                    for t_r in table_regions:
-                        table = Table(region, textlines=None, rect=t_r,
-                                      paragraph=p).extract()
+        for region_number, region in enumerate(self.regions):
+            if region.top < 10:
+                self.find_header(region, region_number == 1, titles)
+            if len(region.text_lines) > 0:
+                paragraphs = self.extract_paragraph(region)
+                doc_paragraph=None
+                for paragraph in paragraphs:
+                    last_paragraph=self.document._paragraphs.get_last_paragraph()
+                    if last_paragraph is None:
+                        doc_paragraph = self.document._paragraphs.create_paragraph()
+                    if isinstance(paragraph, Chart):
+                        if doc_paragraph is not None:
+                            doc_paragraph.add_content(paragraph, ContentType.Chart)
+                        elif last_paragraph is not None:
+                            last_paragraph.add_content(paragraph, ContentType.Chart)
+                        continue
+                    elif isinstance(paragraph, Table):
+                        if doc_paragraph is not None:
+                            doc_paragraph.add_content(paragraph, ContentType.Table)
+                        elif last_paragraph is not None:
+                            last_paragraph.add_content(paragraph, ContentType.Table)
+                        continue
+                    for line in paragraph:
+                        if self.is_title(line, title_font, self.font_statistics):
+#                            print(line)
+                            if last_paragraph is not None and last_paragraph.title==line:
+                                continue
 
-                elif text_lines:
-                    table = Table(region, textlines=text_lines if text_lines else p, rect=table_region, paragraph=p).extract()
-                else:
-                    paragraph=p
-                if table is not None:
-                    while i < len(p):
-                        line=p[i]
-                        if table is None or line not in table.textlines:
-                            paragraph.append(line)
-                            i+=1
+                            doc_paragraph = self.document._paragraphs.create_paragraph()
+                            doc_paragraph.title=line
                         else:
-                            paragraph.append(table)
-                            i += len(table.textlines)
-                returned_paragraphs.append(paragraph)
-        return returned_paragraphs
+                            if doc_paragraph is not None:
+                                doc_paragraph.add_content(line, ContentType.Text)
+                            elif last_paragraph is not None:
+                                last_paragraph.add_content(line, ContentType.Text)
+
 
     def extract_paragraph_bk(self, region):
-        returned_paragraphs= []
+        returned_paragraphs = []
 
-        g_paragraph=self.extract_paragaph_from_graph(region)
+        g_paragraph = self.extract_paragaph_from_graph(region)
 
         if g_paragraph:
-            returned_paragraphs=g_paragraph
+            returned_paragraphs = g_paragraph
         else:
             txt_paragraphs = extract(region.text_lines)
 
             for p in txt_paragraphs:
                 paragraph = []
-                table_region=None
+                table_region = None
                 text_lines = Table.extract_table_lines_from_paragaraph(p)
                 table_regions = utils.get_partially_overlapping_objects(
                     utils.get_BoundingBox_from_objects([t for l in p for t in l]), region.tables)
                 if table_regions:
-                    table_region=utils.get_BoundingBox_from_objects(table_regions)
+                    table_region = utils.get_BoundingBox_from_objects(table_regions)
 
                 if text_lines or table_region:
-                    i=0
-                    table = Table(region, textlines=text_lines if text_lines else p, rect=table_region, paragraph=p).extract()
+                    i = 0
+                    table = Table(region, textlines=text_lines if text_lines else p, rect=table_region,
+                                  paragraph=p).extract()
                     while i < len(p):
-                        line=p[i]
+                        line = p[i]
                         if table is None or line not in table.textlines:
                             paragraph.append(line)
-                            i+=1
+                            i += 1
                         else:
                             paragraph.append(table)
                             i += len(table.textlines)
                 else:
-                    paragraph=p
+                    paragraph = p
 
                 returned_paragraphs.append(paragraph)
         return returned_paragraphs
 
-    def extract_paragaph_from_graph(self, region):
+    def extract_paragraph(self, region):
+
+        returned_paragraphs = []
+        g_paragraph=self.extract_paragaph_from_graph(region)
+        t_paragraph=self.extract_paragaph_from_table(region)
 
+        if g_paragraph:
+            returned_paragraphs.extend(g_paragraph)
+        elif t_paragraph:
+            returned_paragraphs.extend(t_paragraph)
+        else:
+            returned_paragraphs.extend(extract(region.text_lines))
 
-        if len(region.charts)==0:
+        return returned_paragraphs
+
+    def extract_paragaph_from_graph(self, region):
+
+        if len(region.charts) == 0:
             return []
         else:
             top = region.top
             paragraphs = []
             for graph in sorted(region.charts, key=lambda g: g.top):
-                top_paragraph = extract([tl for tl in region.text_lines if top < tl[0].top <= graph.top])
+                top_paragraph = extract([tl for tl in region.text_lines if top < tl[0].bottom <= graph.top])
                 if len(top_paragraph[0]) > 0:
                     paragraphs.extend(top_paragraph)
-                graph_paragraph = []
-                graph_data = graph.extract_chart_data()
-                if 'text' in graph_data and len(graph_data['text']) > 0:
-                    graph_paragraph.append(graph_data['text'])
-                if 'dataframe' in graph_data and graph_data['dataframe'] is not None:
-                    graph_paragraph.append(graph_data['dataframe'])
-                paragraphs.append(graph_paragraph)
+                # graph_paragraph = []
+                # graph_data = graph.extract_chart_data()
+                # if 'text' in graph_data and len(graph_data['text']) > 0:
+                #     graph_paragraph.append(graph_data['text'])
+                # if 'dataframe' in graph_data and graph_data['dataframe'] is not None:
+                #     graph_paragraph.append(graph_data['dataframe'])
+                paragraphs.append(graph)
 
                 top = graph.bottom
             last_paragraph = extract([tl for tl in region.text_lines if tl[0].top > top])
             if len(last_paragraph[0]) > 0:
                 paragraphs.extend(last_paragraph)
 
         return paragraphs
 
+    def extract_paragaph_from_table(self, region):
+
+        if len(region.tables) == 0:
+            return []
+        else:
+            top = region.top
+            paragraphs = []
+            if len(region.tables)>1:
+                txt_paragraphs=extract(region.text_lines)
+                for p in txt_paragraphs:
+                    table_region = utils.get_partially_overlapping_objects(
+                        utils.get_BoundingBox_from_objects([t for l in p for t in l]), region.tables)
+                    if table_region:
+                        text_lines = Table.extract_table_lines_from_paragaraph(p)
+                        table = Table(region, textlines=text_lines, rect=table_region[0], paragraph=p).extract()
+                        if table:
+                            paragraphs.append(table)
+                    else:
+                        paragraphs.append(p)
+            else:
+                table=region.tables[0]
+                top_paragraph = extract([tl for tl in region.text_lines if top < tl[0].bottom <= table.top])
+                if len(top_paragraph[0]) > 0:
+                    paragraphs.extend(top_paragraph)
+                text_lines = Table.extract_table_lines_from_paragaraph(region.text_lines)
+                table = Table(region, textlines= text_lines, rect=table).extract()
+                if table:
+                    paragraphs.append(table)
+
+                    top = table.bottom
+                last_paragraph = extract([tl for tl in region.text_lines if tl[0].top > top])
+                if len(last_paragraph[0]) > 0:
+                    paragraphs.extend(last_paragraph)
+
+        return paragraphs
+
     def is_title2(self, textline, font_stat, page_font_stat, title_font={}, font_body={}):
 
-        if len(textline)==0:
+        if len(textline) == 0:
             return False
-        if font_body and textline[0].font+str(textline[0].Text.isupper() or textline[0].is_bold)==font_body['name'] and textline[0].font_size==font_body['size']:
+        if font_body and textline[0].font + str(textline[0].Text.isupper() or textline[0].is_bold) == font_body[
+            'name'] and textline[0].font_size == font_body['size']:
             return False
 
-        if utils.get_type(textline[0].Text.replace('M', '').replace('', '').replace('/', '').strip())== "Numeric":
+        if utils.get_type(textline[0].Text.replace('M', '').replace('', '').replace('/', '').strip()) == "Numeric":
             return False
-        if title_font and textline[0].font+str(textline[0].Text.isupper() or textline[0].is_bold)==title_font['name']:
+        if title_font and textline[0].font + str(textline[0].Text.isupper() or textline[0].is_bold) == title_font[
+            'name']:
             return True
-        elif title_font and textline[0].font_size>title_font['size']:
+        elif title_font and textline[0].font_size > title_font['size']:
             return True
         elif title_font:
             return False
-        if (len(font_stat["name_by_frequency"]) > 1 or len(font_stat["size_by_frequency"]) > 1) and (textline[0].font_size >= font_stat['second_largest'] and font_stat['second_largest']>-1):
-            title_font['name']= textline[0].font+str(textline[0].Text.isupper() or textline[0].is_bold)
-            title_font['size']=textline[0].font_size
+        if (len(font_stat["name_by_frequency"]) > 1 or len(font_stat["size_by_frequency"]) > 1) and (
+                textline[0].font_size >= font_stat['second_largest'] and font_stat['second_largest'] > -1):
+            title_font['name'] = textline[0].font + str(textline[0].Text.isupper() or textline[0].is_bold)
+            title_font['size'] = textline[0].font_size
             return True
         elif len(font_stat["name_by_frequency"]) == 1 and len(font_stat["size_by_frequency"]) == 1:
-            if font_stat['most_frequent']< page_font_stat["largest"]:
+            if font_stat['most_frequent'] < page_font_stat["largest"]:
                 return False
-            elif font_stat['most_frequent']== page_font_stat["largest"] and (textline[0].Text.isupper() or textline[0].is_bold):
-                title_font['name']=textline[0].font+str(textline[0].Text.isupper() or textline[0].is_bold)
-                title_font['size']=textline[0].font_size
+            elif font_stat['most_frequent'] == page_font_stat["largest"] and (
+                    textline[0].Text.isupper() or textline[0].is_bold):
+                title_font['name'] = textline[0].font + str(textline[0].Text.isupper() or textline[0].is_bold)
+                title_font['size'] = textline[0].font_size
                 return True
-            elif font_stat['most_frequent']== page_font_stat["largest"]:
+            elif font_stat['most_frequent'] == page_font_stat["largest"]:
                 return False
         return False
 
-    def find_header(self, region, largest_only=False):
-        font_stat= region.parent_page.font_statistics
+    def find_header(self, region, first_page=False, titles=None):
+        font_stat = region.parent_page.font_statistics
+        for i, l in enumerate(region.text_lines[:5]):
+            if (l[0].top >= self.root_page.height / 8 and i > 2) or l in titles:
+                continue
+            if l[0].font_size == font_stat["largest"] or l[0].font_size >= font_stat['second_largest']:
+                self.title.append(l)
+                if first_page or l[0].font_size == font_stat["largest"]:
+                    region.text_lines.remove(l)
+
+        return False
+
+    def find_header_bk(self, region, largest_only=False):
+        font_stat = region.parent_page.font_statistics
         first_horizontal_separator = None
-        horizontal_separators = [line for line in region.horizontal_lines+region.horizontal_edges if line.width > self.width * 0.7 and line.top>10]
+        horizontal_separators = [line for line in region.horizontal_lines + region.horizontal_edges if
+                                 line.width > self.width * 0.7]
         if len(horizontal_separators) > 0:
             first_horizontal_separator = horizontal_separators[0]
         for l in region.text_lines[:5]:
-            if first_horizontal_separator and l[0].top > first_horizontal_separator.top and len(self.title)>0:
+            if first_horizontal_separator and l[0].top > first_horizontal_separator.top and len(self.title) > 0:
                 return
 
-            if not largest_only and (l[0].font_size == font_stat["largest"] or l[0].font_size > font_stat["most_frequent"]):
+            if not largest_only and (
+                    l[0].font_size == font_stat["largest"] or l[0].font_size > font_stat["most_frequent"]):
                 self.title.append(l)
                 region.text_lines.remove(l)
             elif largest_only and l[0].font_size == font_stat["largest"]:
                 self.title.append(l)
                 region.text_lines.remove(l)
         return False
 
-    def is_title(self, id, region_number, line, font_stat, title_font={}):
+    def is_title(self, line, title_font, font_stat={}):
 
-        if len(line)>1:
+#        return line in titles
+        if len(line)>1 or not line[0].Text.istitle():
             return False
 
-        if line[0].font_size >= font_stat["most_frequent"] and region_number == 0 and id<3:
+        if line[0].font_size >= font_stat["second_largest"]:
             title_font['font']=line[0].font
             return True
 
         if title_font:
             if line[0].font == title_font['font']:
                 return True
             else:
                 return False
 
         if len(line)==1 and utils.get_type(line[0].Text)=="Numeric":
             return False
 
-        if line[0].font_size > font_stat["most_frequent"]:
-            title_font['font']=line[0].font
-            return True
-
-
-
         if len(font_stat["size_by_frequency"])==1 and line[0].is_bold:
             title_font['font']=line[0].font
             return True
 
         if len(font_stat["size_by_frequency"])==1 and len(font_stat["name_by_frequency"])==1:
             return False
 
         if id==0:
             title_font['font'] = line[0].font
             return True
 
         return False
 
+    def _has_match(self, sorted_list, item):
+        #       show_rects_and_wait(sorted_list, self.page_image)
+        i = 0
+        while i < len(sorted_list) and not isclose(sorted_list[i].top, item.top, abs_tol=item.height / 3):
+            i += 1
+
+        return_set = []
+        if i < len(sorted_list):
+            while i < len(sorted_list) and isclose(sorted_list[i].top, item.top, abs_tol=item.height / 3):
+                return_set.append(sorted_list[i])
+                i += 1
+        if return_set == []:
+            return False
+        else:
+            for t in return_set:
+                intersection = rectangle_intersect((item.left, item.top, item.right, item.bottom),
+                                                   (t.left, t.top, t.right, t.bottom), norm_intersect_area='a')
+                if intersection and intersection > 0.5:
+                    return True
+        return False
 
     def set_page_layout(self):
 
-
         mediabox = self.page_obj.attrs.get("MediaBox")
 
         self.mediabox = resolve_all(mediabox)
 
-
-        self.image_width = self.image.shape[1]
-        self.image_height = self.image.shape[0]
+        self.image_width = self.page_image.shape[1]
+        self.image_height = self.page_image.shape[0]
         self.x_scaler = self.image_width / float(self.mediabox[2])
         self.y_scaler = self.image_height / float(self.mediabox[3])
 
-
-
     def get_token_with_value(self, val):
         for t in self.tokens:
-            if t.Text==val:
+            if t.Text == val:
                 return t
 
     @property
     def regions(self):
         if hasattr(self, "_regions"):
             return self._regions
-        self._regions=[]
-        all_regions_=[sorted(re, key=lambda x: ( x.left, x.top)) for re in self._region_extractor.extract_regions()]
 
+        self._regions = []
+        for chart in self.charts:
+            cv2.line(self.page_image, (int(chart.left) + 5, int(chart.top) + 5),
+                     (int(chart.right) - 5, int(chart.bottom) - 5), (0, 0, 255), 3)
+
+
+        _regions_ = PageAnalyzer(self).extract_regions()
+
+        # recombine small regions horizontally
+        all_regions = []
+        for sub_region in _regions_:
+
+            for region in sorted(sub_region, key=lambda x: (x.top, x.left)):
+                texts1 = utils.get_widthin_BoundingBox(self.text_lines, region)
+                texts2 = utils.get_widthin_BoundingBox(self.text_lines, all_regions[-1]) if len(all_regions) else 3
+
+                if len(all_regions) == 0 or len(texts1) > 2 and len(texts2) > 2:
+                    all_regions.append(region)
+                elif all_regions[-1].top == region.top and all_regions[-1].bottom == region.bottom:
+                    all_regions[-1].right = region.right
+                else:
+                    all_regions.append(region)
 
-        for regions in all_regions_:
-            self._regions.extend([Region(self, r) for r in regions])
+        all_regions_ = []
+        for region in sorted(all_regions, key=lambda x: (x.left, x.top)):
+            texts1 = utils.get_widthin_BoundingBox(self.tokens, region)
+            texts2 = utils.get_widthin_BoundingBox(self.tokens, all_regions_[-1]) if len(all_regions_) else 4
+
+            if len(all_regions_) == 0 or len(texts1) > 3 and len(texts2) > 3:
+                all_regions_.append(region)
+            elif all_regions_[-1].left == region.left and all_regions_[-1].right == region.right:
+                all_regions_[-1].bottom = region.bottom
+            else:
+                all_regions_.append(region)
 
-        self._regions=[r for r in self._regions if len(r.text_lines)>0]
+        all_regions_ = [Region(self, r) for r in all_regions_]
+        self._regions = sorted([r for r in all_regions_ if len(r.text_lines) > 0], key=lambda re: (re.left, re.top))
 
+        #        self._regions=sorted(self._regions, key=lambda re: (re.left, re.top))
         return self._regions
 
     @property
     def width(self):
         return self.bbox.right - self.bbox.left
 
     @property
@@ -372,26 +517,25 @@
         return self._layout
 
     @property
     def font_statistics(self):
         if hasattr(self, "_font_statistics"):
             return self._font_statistics
 
-        self._font_statistics = utils.get_fonts_statistics(self.tokens)
+        self._font_statistics = utils.get_fonts_statistics(self.text_lines)
         return self._font_statistics
 
-
     @property
     def objects(self):
         if hasattr(self, "_objects"):
             return self._objects
-        self.parse_objects(self.x_scaler, self.y_scaler)
+        self._objects = self.parse_objects()
         return self._objects
 
-    def process_object(self, obj, scaler_x, scaler_y):
+    def process_object(self, obj):
         kind = re.sub(lt_pat, "", obj.__class__.__name__).lower()
 
         def process_attr(item):
             k, v = item
             if k in ALL_ATTRS:
                 res = resolve_all(v)
                 return (k, res)
@@ -409,49 +553,48 @@
             attr["non_stroking_color"] = gs.ncolor
             attr["linewidth"] = gs.linewidth
 
         if hasattr(obj, "get_text"):
             attr["text"] = obj.get_text()
 
         if kind == "curve":
-
             def point2coord(pt):
                 x, y = pt
                 return (x, self.height - y)
 
             attr["points"] = list(map(point2coord, obj.pts))
 
         if attr.get("y0") is not None:
-            attr["top"] = self.height - attr["y1"]*scaler_y
-            attr["bottom"] = self.height - attr["y0"]*scaler_y
+            attr["top"] = (self.height - attr["y1"]) * self.y_scaler
+            attr["bottom"] = (self.height - attr["y0"]) * self.y_scaler
         if attr.get("x0") is not None:
-            attr["left"] =  attr["x0"]*scaler_x
+            attr["left"] = attr["x0"] * self.x_scaler
         if attr.get("x1") is not None:
-            attr["right"] = attr["x1"]*scaler_x
+            attr["right"] = attr["x1"] * self.x_scaler
 
         return attr
 
-    def iter_layout_objects(self, layout_objects, scaler_x, scaler_y):
+    def iter_layout_objects(self, layout_objects):
         for obj in layout_objects:
             # If object is, like LTFigure, a higher-level object
             # then iterate through it's children
             if hasattr(obj, "_objs"):
-                yield from self.iter_layout_objects(obj._objs,scaler_x=scaler_x, scaler_y=scaler_y)
+                yield from self.iter_layout_objects(obj._objs)
             else:
-                yield self.process_object(obj, scaler_x=scaler_x, scaler_y=scaler_y)
+                yield self.process_object(obj)
 
-    def parse_objects(self, scaler_x, scaler_y):
+    def parse_objects(self):
         objects = {}
-        for obj in self.iter_layout_objects(self.layout._objs, scaler_x=scaler_x, scaler_y=scaler_y):
+        for obj in self.iter_layout_objects(self.layout._objs):
             kind = obj["object_type"]
 
             if objects.get(kind) is None:
                 objects[kind] = []
             objects[kind].append(obj)
-        self._objects=objects
+        return objects
 
     def within_bbox(self, bbox, relative=False):
         """
         Same as .crop, except only includes objects fully within the bbox
         """
         return Region(self, bbox)
 
@@ -461,66 +604,89 @@
             return self._tables
 
         self._tables = self.table_finder.guess_tables()
         return self._tables
 
     @property
     def charts(self):
-        if hasattr(self, "_graphs"):
+        if hasattr(self, "_charts"):
             return self._charts
 
+        self._charts = extract_charts(page=self, rect_threshold=2)
 
-        self._charts=extract_charts(page=self, rect_threshold=2)
         return self._charts
 
     @property
     def words(self):
         settings = dict(DEFAULT_WORD_EXTRACTION_SETTINGS)
         if self._words:
             return self._words
+        if not self.chars:
+            return []
+        chars = self.chars
 
-        if self._page_pdf.words!=[]:
-            self._words= [Word(w, self) for w in self._page_pdf.words]
+        if "linewidth" in self.chars[0]:
+            chars = [char for char in self.chars if
+                     (char["upright"] and (char["left"] > 0 and char["linewidth"] > 0) or (
+                             char["linewidth"] == 0 and char["non_stroking_color"] not in [(1, 0, 1)]))]
+        self._words = WordExtractor(self, **settings).extract(chars)
+        if self.alto is not None:
+            return [w for w in self._words if
+                    self._has_match(sorted([t for t in self.alto.extract_text_lines()], key=lambda x: x.top), w)]
         return self._words
 
     @property
     def tokens(self):
         if self.token_start is not None and self.token_end is not None:
             return self.document._token_list[self.token_start:self.token_end]
 
         settings = dict(DEFAULT_TOKEN_EXTRACTION_SETTINGS)
 
-        self.token_start=len(self.document._token_list)
-
-        if self._page_pdf.text_lines:
-            _tokens=[Token(t, self) for t in self._page_pdf.text_lines]
+        self.token_start = len(self.document._token_list)
+        if self.words != []:
+            _tokens = TokenExtractor(self, **settings).extract(self.words)
         else:
-            _tokens=TokenExtractor(self, **settings).extract(self._page_pdf.words)
+            _tokens = []
+
+        not_tokens = [t for t in _tokens if t.left < 1 or t.right < 1 or t.top < 1 or t.bottom < 1]
 
         for i, token in enumerate(_tokens):
-            token.index=self.token_start+i
+            if hasattr(token.original_words[0], "font_color"):
+                print(token.Text)
+            if token in not_tokens:
+                continue
+            token.index = self.token_start + i
             self.document._token_list.append(token)
 
-        self.token_end=len(self.document._token_list)
+        self.token_end = len(self.document._token_list)
         return self.document._token_list[self.token_start:self.token_end]
 
     @property
     def text_lines(self):
 
-        if self.__text_lines is not None:
-            return self.__text_lines
-        if len(self.tokens)==0:
+        if self._text_lines is not None:
+            return self._text_lines
+        if len(self.tokens) == 0:
             return []
- #       doctop_clusters = cluster_objects(self.tokens, "bottom", self.tokens[0].font_size/3)
+            #       doctop_clusters = cluster_objects(self.tokens, "bottom", self.tokens[0].font_size/3)
+
+            #        if doctop_clusters is not None:
+        self._text_lines = utils.find_line_structure(
+            self.tokens)  # [sorted(line, key=lambda x: x.left) for line in doctop_clusters]
+        if not isinstance(self, Region):
+            for i in range(1, len(self._text_lines)):
+                for token in self._text_lines[i]:
+                    token.space_above = self._text_lines[i][0].bottom - self._text_lines[i - 1][0].bottom
+
+            if len(self._text_lines)>=2:
+                for token in self._text_lines[0]:
+                    token.space_above=max(a[0].space_above for a in self._text_lines[1:])
 
-#        if doctop_clusters is not None:
-        tls = sorted(utils.find_line_structure(self.tokens), key=lambda x:x[0].top)#[sorted(line, key=lambda x: x.left) for line in doctop_clusters]
 
-        self.__text_lines=tls
-        return self.__text_lines
+        return self._text_lines
 
     def __repr__(self):
         return f"<Page:{self.page_number}>"
 
     @property
     def top(self):
         return self.bbox.top
@@ -536,92 +702,90 @@
     @property
     def right(self):
         return self.bbox.right
 
     @property
     def left_margin(self):
         if self._left_margin is None:
-            if len(self.tokens)==0:
-                self._left_margin=0
+            if len(self.tokens) == 0:
+                self._left_margin = 0
             else:
                 self._left_margin = min([t.left for t in self.tokens])
 
         return self._left_margin
 
     @property
     def content_width(self):
-        return self.right_margin-self.left_margin
+        return self.right_margin - self.left_margin
 
     @property
     def right_margin(self):
         if self._right_margin is None:
-            if len(self.tokens)==0:
-                self._right_margin=self.width
+            if len(self.tokens) == 0:
+                self._right_margin = self.width
             else:
                 self._right_margin = max([t.right for t in self.tokens])
-            if self._right_margin>=self.bbox.right:
-                self._right_margin=self.bbox.right-self.left_margin/2
+            if self._right_margin >= self.bbox.right:
+                self._right_margin = self.bbox.right - self.left_margin / 2
         return self._right_margin
 
     @property
     def top_margin(self):
         if self._top_margin is None:
-            if len(self.tokens)==0:
-                self._top_margin=0
+            if len(self.tokens) == 0:
+                self._top_margin = 0
             else:
                 self._top_margin = min([t.top for t in self.tokens])
         return self._top_margin
 
     @property
     def bottom_margin(self):
         if self._bottom_margin is None:
-            if len(self.tokens)==0:
-                self._bottom_margin=self.height
+            if len(self.tokens) == 0:
+                self._bottom_margin = self.height
             else:
                 self._bottom_margin = max([t.bottom for t in self.tokens])
         return self._bottom_margin
 
+
 class Region(Page):
     is_original = False
 
     def __init__(self, parent_page, bbox):
 
         self.parent_page = parent_page
         self.page_number = parent_page.page_number
 
-        super().__init__(parent_page, parent_page._page_pdf, parent_page.page_obj, bbox=bbox)
+        super().__init__(parent_page, parent_page.page_obj, bbox=bbox)
         self.flush_cache(Component.cached_properties)
-        self.image=self.parent_page.image[bbox.top:bbox.bottom, bbox.left:bbox.right]
-        self.bbox=bbox
+        self.page_image = self.parent_page.page_image[bbox.top:bbox.bottom, bbox.left:bbox.right]
+        self.bbox = bbox
 
         if type(parent_page) == Page:
             self.root_page = parent_page
         else:
             self.root_page = parent_page.root_page
-        self.sections=[]
-
+        self.sections = []
 
     def __repr__(self):
         return f"<Region:{self.page_number}>"
 
     @property
     def rects(self):
         return utils.get_widthin_BoundingBox(self.parent_page.rects, self.bbox)
 
     @property
     def words(self):
-        return utils.get_widthin_BoundingBox(self.parent_page.wods, self.bbox)
-    @property
-    def objects(self):
-        if hasattr(self, "_objects"):
-            return self._objects
-        self._objects = utils.get_widthin_bbox(self.parent_page.objects, self.bbox)
-        return self._objects
+        return utils.get_widthin_BoundingBox(self.parent_page.words, self.bbox)
 
     @property
     def tokens(self):
-        if hasattr(self, "_tokens"):
-            return self._tokens
+        return utils.get_widthin_BoundingBox(self.parent_page.tokens, self.bbox)
 
-        self._tokens=utils.get_widthin_BoundingBox(self.parent_page.tokens, self.bbox)
+    @property
+    def charts(self):
+        return utils.get_widthin_BoundingBox(self.parent_page.charts, self.bbox)
+
+    @property
+    def objects(self):
+        return utils.get_widthin_BoundingBox(self.parent_page.objects, self.bbox)
 
-        return self._tokens
```

## pdf2txt/core/paragraph.py

```diff
@@ -2,23 +2,63 @@
 
 from collections import defaultdict
 import statistics
 from pdf2txt.exceptions import ParagraphNotFoundError
 import numpy as np
 from enum import Enum
 from pandas import DataFrame
-from string import digits
+from sklearn.cluster import AgglomerativeClustering
 from pdf2txt.core.indexer import *
+from gower import gower_matrix
+from statistics import mean
+from pdf2txt.utils import join_lines
 if TYPE_CHECKING:
     from pdf2txt.core import Document, Token
 
+import pandas as pd
 
 
+def guess_titles(raw_text, font_stats):
+
+    if len(raw_text)<2:
+        return([])
+    coordinates = pd.DataFrame([(c[0].font_name, c[0].font_size, c[0].Text.isupper(), c[0].is_bold, sum([len(i.Text) for i in c]), sum([len(i.Text.split(' ')) for i in c])) for c in raw_text])
+
+    distance_matrix = gower_matrix(coordinates)
+
+    clustering = AgglomerativeClustering(
+        n_clusters=None,
+        linkage="complete",
+        distance_threshold=0.5)
+    clustering.fit(distance_matrix)
+    # initialize our list of sorted clusters
+    titles = []
+
+    # loop over all clusters
+    for l in np.unique(clustering.labels_):
+        # extract the indexes for the coordinates belonging to the # current cluster
+        idxs = np.where(clustering.labels_ == l)[0]
+
+
+        lines= [raw_text[i] for i in idxs]
+
+        titles.append(lines)
+
+    titles_=sorted([t for t in titles if len(t)>1], key=lambda x: len(x))[:-1]
+    font_size_cut_off=max(font_stats['average'], font_stats['most_frequent'])+0.1
+
+    titles_=[l for l in titles_ if mean([t[0].font_size for t in l])>=max(font_size_cut_off,font_stats['size_by_frequency'][0]) and mean([len(t) for t in l])<=2]
+    return [t for l in titles_ for t in  l]
+
 
 def extract(textlines):
+        textlines=[t for t in textlines if (len(t[0].Text)>=1 and len(t)>1) or len(t[0].Text)>1]
+        for t in textlines:
+            while len(t)>=2 and len(t[0].Text)==1:
+                t.pop(0)
 
         if len(textlines)<=2:
             return [textlines]
 
         # normalizing the line gaps to get an average gap for detetcting the paraagarphs
         line_gap_list=[j[0].bottom-i[0].bottom+(1+j[0].is_bold)*j[0].font_size for i, j in zip(textlines[:-1], textlines[1:])]
 #        line_gap_list = [line.space_above+line.tokens[0].font_size for line in textlines if line.space_above != -1]
@@ -26,15 +66,15 @@
             line_gap_list.insert(0, 0 if len(line_gap_list) else 0)
         #	curr_line=[line.Text for line in textlines]
 
         if len(line_gap_list) <= 3:
             return [textlines]
 
         # Now we need the 2nd order derivative so that we can  get the
-        # global maxima to get the paragraphs
+        # global maxima to get the _paragraphs
         # 2nd order derivative is defined as :
         # f(x+1,y) + f(x-1,y) -2*f(x,y) ----> in the x direction
         # f(x,y+1) + f(x,y-1) -2*f(x,y) ----> in the y direction
         # we only need the derivative in the y direction here
 
         derivative_line_gap = line_gap_list
         for i in range(0, len(line_gap_list) - 1):
@@ -73,15 +113,14 @@
         zero_crossings.insert(len(zero_crossings), len(textlines))
 
         paragraph_ranges = [(zero_crossings[i], zero_crossings[i + 1]) for i in range(len(zero_crossings) - 1)]
         paragraphs= [textlines[i:j] for i, j in paragraph_ranges]
 
         return paragraphs
 
-
 def extract2(textlines):
     if len(textlines) <= 2:
         return [textlines]
 
     # normalizing the line gaps to get an average gap for detetcting the paraagarphs
     line_gap_list = [j[0].bottom - i[0].bottom + j[0].font_size for i, j in
                      zip(textlines[:-1], textlines[1:])]
@@ -90,15 +129,15 @@
         line_gap_list.insert(0, max(line_gap_list) if len(line_gap_list) else 0)
     #	curr_line=[line.Text for line in textlines]
 
     if len(line_gap_list) <= 3:
         return [textlines]
 
     # Now we need the 2nd order derivative so that we can  get the
-    # global maxima to get the paragraphs
+    # global maxima to get the _paragraphs
     # 2nd order derivative is defined as :
     # f(x+1,y) + f(x-1,y) -2*f(x,y) ----> in the x direction
     # f(x,y+1) + f(x,y-1) -2*f(x,y) ----> in the y direction
     # we only need the derivative in the y direction here
 
     derivative_line_gap = line_gap_list
     for i in range(0, len(line_gap_list) - 1):
@@ -133,20 +172,18 @@
     zero_crossings.insert(len(zero_crossings), len(textlines))
 
     paragraph_ranges = [(zero_crossings[i], zero_crossings[i + 1]) for i in range(len(zero_crossings) - 1)]
     paragraphs = [textlines[i:j] for i, j in paragraph_ranges]
 
     return paragraphs
 
-
-
 class ContentType(Enum):
     Text=1
     Table=2
-    Graph=3
+    Chart=3
 
 class Paragraph:
     """
     A continuous group of tokens within a document.
 
     A paragraph is intended to label a group of tokens. Said tokens must be continuous
     in the document.
@@ -154,15 +191,15 @@
     Warning:
         You should not instantiate a PDFParagraph class yourself, but should call
         `create_paragraph` from the `PDFParagraphing` class below.
 
     Args:
         document (PDFDocument): A reference to the document.
         name (str): The name of the paragraph.
-        unique_name (str): Multiple paragraphs can have the same name, but a unique name
+        unique_name (str): Multiple _paragraphs can have the same name, but a unique name
             will be generated by the PDFParagraphing class.
         start_token (PDFToken): The first token in the paragraph.
         end_token (PDFToken): The last token in the paragraph.
     """
 
     document: "Document"
     name: str
@@ -223,32 +260,35 @@
 
 
     @property
     def Text(self):
         return_str=""
         if self.title:
             return_str = ' '.join([t.Text for t in self.title]) + '\n'
-            return_str += '-' * len(return_str)
+
         for content in self.content:
             if content["type"]==ContentType.Text:
                 return_str += '\n' + ' '.join([c.Text for c in content["content"]])
-            elif content["type"]==ContentType.Graph:
-                return_str+="<START GRAPH DATA>\n"
-                return_str+='\n'+content["content"].to_string(index=False)
-                return_str+="\n<END GRAPH DATA>"
+            elif content["type"]==ContentType.Chart:
+                chart_data=content["content"].extract_chart_data()
+                if chart_data["dataframe"] is  None:
+                    continue
+                return_str+="\n<START GRAPH DATA>\n"
+                return_str+='\n'+chart_data["dataframe"].to_string(index=False)
+                return_str+="\n<END GRAPH DATA>\n"
             elif content["type"]==ContentType.Table:
                 return_str+="\n<START TABLE>\n"
                 return_str+='\n'+content["content"].to_string(index=False)
-                return_str+="\n<END TABLE>"
-        return return_str
+                return_str+="\n<END TABLE>\n"
+        return join_lines(return_str)
 
 
     def __eq__(self, other: object) -> bool:
         """
-        Returns True if the two paragraphs have the same unique name and are from the
+        Returns True if the two _paragraphs have the same unique name and are from the
         same document
         """
         if not isinstance(other, Paragraph):
             raise NotImplementedError(f"Can't compare PDFParagraph with {type(other)}")
         return all(
             [
                 self.document == other.document,
@@ -325,15 +365,15 @@
 
     def create_paragraph(  self, name=None):
         """
         Creates a new paragraph with the specified name.
 
         Creates a new paragraph with the specified name, starting at `start_token` and
         ending at `end_token` (inclusive). The unique name will be set to name_<idx>
-        where <idx> is the number of existing paragraphs with that name.
+        where <idx> is the number of existing _paragraphs with that name.
 
         Args:
             name (str): The name of the new paragraph.
             start_token (PDFToken): The first token in the paragraph.
             end_token (PDFToken): The last token in the paragraph.
             include_last_token (bool): Whether the end_token should be included in
                 the paragraph, or only the tokens which are strictly before the end
@@ -344,28 +384,28 @@
 
         Raises:
             InvalidPDFParagraphError: If a the created paragraph would be invalid. This is
                 usually because the end_token comes after the start token.
         """
 
         if name==None:
-            name="paragraph"+str(len(self.document.paragraphs.paragraphs))
+            name="paragraph"+str(len(self.document.paragraphs))
         current_count = self.name_counts[name]
         unique_name = f"{name}_{current_count}"
         self.name_counts[name] += 1
 
-        paragraph = Paragraph(self.document, name, unique_name, paragraph_number=len(self.document.paragraphs.paragraphs))
+        paragraph = Paragraph(self.document, name, unique_name, paragraph_number=len(self.document.paragraphs))
         self.paragraphs_dict[unique_name] = paragraph
         self.paragraphs_dict_by_number[paragraph.number]=unique_name
         self.docnumbers.append(paragraph.number)
         return paragraph
 
     def get_paragraphs_with_name(self, name: str) -> Generator[Paragraph, None, None]:
         """
-        Returns a list of all paragraphs with the given name.
+        Returns a list of all _paragraphs with the given name.
         """
         return (
             self.paragraphs_dict[f"{name}_{idx}"]
             for idx in range(0, self.name_counts[name])
         )
 
     def get_paragraph(self, unique_name: str) -> Paragraph:
```

## pdf2txt/core/token.py

```diff
@@ -1,38 +1,40 @@
 from pdf2txt.utils import get_BoundingBox_from_objects,BoundingBox
 from collections import Counter
-from pdf2txt.settings import DEFAULT_TOKEN_EXTRACTION_SETTINGS
+from pdf2txt.settings import DEFAULT_X_TOLERANCE, DEFAULT_Y_TOLERANCE, DEFAULT_TOKEN_EXTRACTION_SETTINGS
 import copy
 from pdf2txt.utils import are_in_same_Line
-from pdf2txt.core.word import Word
 
-exceptions=['', 'l', '(%)']
 
+start_new_word=['', 'l', '(%)', '', '-']
+continue_word=['*', '(1)']
 class TokenExtractor:
     def __init__(self, page, **settings):
 
         for s, val in settings.items():
             if s not in DEFAULT_TOKEN_EXTRACTION_SETTINGS:
                 raise ValueError(f"{s} is not a valid WordExtractor parameter")
 
             setattr(self, s, val)
 
         self.page=page
 
     def word_begins_new_token(self, current_word, next_word):
 
 
-
-        if current_word.font!=next_word.font and (next_word.Text not in exceptions and  current_word.Text not in exceptions):
+        if current_word.font!=next_word.font and (next_word.Text not in start_new_word and current_word.Text not in start_new_word):
             return True
+        if next_word.Text in  continue_word:
+            return False
+
         if self.fixed_width:
             intraline_tol = self.x_tolerance * 3
 
         else:
-            intraline_tol = next_word.font_width * 1.3
+            intraline_tol = next_word.font_width * 1.6
 
         interline_tol = self.y_tolerance
 
         return (
             (next_word.left > current_word.right + intraline_tol)
             or (next_word.right < current_word.left - intraline_tol)
             or (next_word.top > current_word.bottom - interline_tol)
@@ -89,23 +91,24 @@
     def extract(self, words):
         return list(self.iter_extract(words))
 
 class Token(BoundingBox):
 
     def __init__(self, word, page, index=-1, **kwargs):
 
+#        super().__init__(**kwargs)
         self.page = page
         self.original_words = []
-        self.add(Word(word, page))
+        self.add(word)
         self._index = index
         self.paragraph=None
     @staticmethod
     def copy( token):
         words=copy.copy(token.original_words)
-        newtoken=Token(token.original_words[0].original_word, token.page)
+        newtoken=Token(words[0], token.page)
         for w in words[1:]:
             newtoken.add(w)
         return newtoken
 
     def __eq__(self, other):
         """Overrides the default implementation"""
         if isinstance(other, Token):
@@ -202,20 +205,30 @@
 
     @property
     def bottom(self):
         return self.bbox.bottom
 
     def add(self, other):
         self.original_words.append(other)
+        self.original_words=sorted(self.original_words, key=lambda x:x.x0)
         self.bbox=get_BoundingBox_from_objects(self.original_words)
+        self.initialize_attr()
         return self
 
+    def initialize_attr(self):
+        if hasattr(self, "_font_size"):
+            delattr(self, "_font_size")
+        if hasattr(self, "_font_name"):
+            delattr(self, "_font_name")
+
+
     def combine(self, other_token):
         self.original_words.extend(other_token.original_words)
         self.bbox=get_BoundingBox_from_objects(self.original_words)
+        self.initialize_attr()
         return self
 
 
     @property
     def font_size(self) -> float:
         """
         The size of the font.
@@ -237,14 +250,67 @@
                 for word in self.original_words
             )
         )
         self._font_size = counter.most_common(1)[0][0]
 
         return self._font_size
 
+    @property
+    def scolor(self) -> float:
+        """
+        The size of the font.
+
+        This will be taken from the pdf itself, using the most common size within all
+        the characters in the element.
+
+        Returns:
+            float: The font size of the element, rounded to the font_size_precision of
+                the document.
+        """
+
+        if hasattr(self, "_s_color"):
+            return self._s_color
+
+        counter = Counter(
+            (
+                word.font_scolor
+                for word in self.original_words
+            )
+        )
+        self._s_color = counter.most_common(1)[0][0]
+
+        return self._s_color
+
+
+    @property
+    def ncolor(self) -> float:
+        """
+        The size of the font.
+
+        This will be taken from the pdf itself, using the most common size within all
+        the characters in the element.
+
+        Returns:
+            float: The font size of the element, rounded to the font_size_precision of
+                the document.
+        """
+
+        if hasattr(self, "_n_color"):
+            return self._n_color
+
+        counter = Counter(
+            (
+                word.font_ncolor
+                for word in self.original_words
+            )
+        )
+        self._n_color = counter.most_common(1)[0][0]
+
+        return self._n_color
+
 
     @property
     def font_name(self) -> float:
         """
         The size of the font.
 
         This will be taken from the pdf itself, using the most common size within all
@@ -270,20 +336,8 @@
 
     @property
     def font(self):
         return self.font_name+'+'+str(self.font_size)
 
     @property
     def is_bold(self):
-        if hasattr(self, "_is_bold"):
-            return self._is_bold
-
-        counter = Counter(
-            (
-                word.is_bold
-                for word in self.original_words
-            )
-        )
-        self._is_bold = counter.most_common(1)[0][0]
-
-        return self._is_bold
-
+        return 'bold' in self.font_name.lower()
```

## pdf2txt/core/word.py

```diff
@@ -1,10 +1,11 @@
 from pdf2txt.settings import DEFAULT_WORD_EXTRACTION_SETTINGS
 from pdf2txt.utils import BoundingBox, cluster_objects, get_bbox_from_objects
 from operator import itemgetter
+from statistics import mean
 import itertools
 from collections import Counter
 
 class WordExtractor:
     def __init__(self, page, **settings):
         for s, val in settings.items():
             if s not in DEFAULT_WORD_EXTRACTION_SETTINGS:
@@ -115,18 +116,14 @@
     __font_size_precision = 1
     def __init__(self, word, page=None, index=-1):
 
         super().__init__(word["left"], word["top"], word["right"], word["bottom"])
         self.page = page
         self.original_word = word
         self._index = index
-        if "font" in word:
-            self.__font=word["font"]
-        else:
-            self.__font={"name":"Unknown", "size": word["bottom"]-word["top"], "family":"Unknown"}
 
     def __eq__(self, other):
         """Overrides the default implementation"""
         if isinstance(other, Word):
             return self.Text == other.Text and self.x0 == other.x0 and self.bottom == other.bottom
         return False
 
@@ -149,30 +146,40 @@
 
     @property
     def page_number(self):
         return self.page.page_number
 
     @property
     def Text(self):
-        return self.original_word["value"]
+        return self.original_word["text"]
 
     @property
     def font_name(self) -> str:
         """
         The name of the font.
 
         This will be taken from the pdf itself, using the most common font within all
         the characters in the element.
 
         Returns:
             str: The font name of the element.
         """
-        if self.__font is not None:
-            return self.__font["name"]
+        if self.__font_name is not None:
+            return self.__font_name
 
+        counter = Counter(
+            (
+                character["fontname"]
+                for line in self.original_tokens
+                for character in line
+                if "fontname" in character
+            )
+        )
+        self.__font_name = counter.most_common(1)[0][0]
+        return self.__font_name
 
     @property
     def font(self):
         return self.font_name+'+'+str(self.font_size)
 
 
     @property
@@ -191,49 +198,144 @@
         This will be taken from the pdf itself, using the most common size within all
         the characters in the element.
 
         Returns:
             float: The font size of the element, rounded to the font_size_precision of
                 the document.
         """
-        if self.__font is not None:
-            return self.__font["size"]
+        if self.__font_size is not None:
+            return self.__font_size
+
+        counter = Counter(
+            (
+                character["height"]
+                for character in self.original_word["chars"]
+                if ("height" in character)
+            )
+        )
+        self.__font_size = round(
+            counter.most_common(1)[0][0], self.__font_size_precision
+        )
+        return self.__font_size
+
+    @property
+    def font_width(self) -> float:
+        """
+        The size of the font.
+
+        This will be taken from the pdf itself, using the most common size within all
+        the characters in the element.
+
+        Returns:
+            float: The font size of the element, rounded to the font_size_precision of
+                the document.
+        """
+        if self.__font_width is not None:
+            return self.__font_width
 
+        # counter = Counter(
+        #     (
+        #         character["width"]
+        #         for character in self.original_word["chars"]
+        #         if ("width" in character)
+        #     )
+        # )
+        widths=[character["width"] for character in self.original_word["chars"] if ("width" in character)]
 
+        self.__font_width = mean(widths)
+        return self.__font_width
 
 
     @property
     def font_name(self):
         """
         The size of the font.
 
         This will be taken from the pdf itself, using the most common size within all
         the characters in the element.
 
         Returns:
             float: The font size of the element, rounded to the font_size_precision of
                 the document.
         """
-        if self.__font is not None:
-            return self.__font["family"]
+        if hasattr(self, "_fontname"):
+            return self._font_name
+
+        counter = Counter(
+            (
+                character["fontname"]
+                for character in self.original_word["chars"]
+                if ("fontname" in character)
+            )
+        )
+
+        self._font_name = counter.most_common(1)[0][0]
+
+        return self._font_name
+
+    @property
+    def font_scolor(self):
+        """
+        The size of the font.
+
+        This will be taken from the pdf itself, using the most common size within all
+        the characters in the element.
+
+        Returns:
+            float: The font size of the element, rounded to the font_size_precision of
+                the document.
+        """
+        if hasattr(self, "_font_s_color"):
+            return self._font_s_color
+        try:
+            counter = Counter(
+                (
+                    character["stroking_color"]
+                    for character in self.original_word["chars"]
+                    if ("stroking_color" in character)
+                )
+            )
+
+            self._font_s_color = counter.most_common(1)[0][0]
+        except:
+            self._font_s_color=""
+        return self._font_s_color
+
     @property
-    def font_color(self):
+    def font_ncolor(self):
         """
         The size of the font.
 
         This will be taken from the pdf itself, using the most common size within all
         the characters in the element.
 
         Returns:
             float: The font size of the element, rounded to the font_size_precision of
                 the document.
         """
-        if self.__font is  not None:
-            return self.__font["color"]
+        if hasattr(self, "_font_n_color"):
+            return self._font_n_color
+        try:
+            counter = Counter(
+                    (
+                        character["non_stroking_color"]
+                        for character in self.original_word["chars"]
+                        if ("non_stroking_color" in character and character["non_stroking_color"] is not None)
+                    )
+                )
+
+            self._font_n_color = counter.most_common(1)[0][0]
+        except:
+            self._font_n_color = ""
+
+        return self._font_n_color
 
     @property
     def is_bold(self):
-        if "is_bold" in self.original_word:
-            return self.original_word["is_bold"]
-        return False
-
+        return 'bold' in self.font_name.lower()
 
+    @property
+    def ignored(self) -> bool:
+        """
+        A flag specifying whether the element has been ignored.
+        """
+        return self._index in self.document._ignored_indexes
```

## pdf2txt/doc_analyzer/image_analyzer.py

```diff
@@ -33,24 +33,24 @@
         return self.__raw_image
 
     def analyze_page(self):
         self.__ccs_text = get_connected_components(self.__processed)
         self.__image_blocks=TextSegmenter(self.__processed, self.__ccs_text,
                              self.__src, self.__debug).segment_text()
 
-        for text_block in self.__page.text_lines:
-            if "value" in text_block:
-                if text_block['value']=="" or text_block["width"]<=3 or text_block["top"]>self.__page.page_image.shape[0]/5:
-                    continue
-                if text_block['value'].strip()=="":
-                    continue
-            x, y, w, h = int(text_block["left"]),int(text_block["top"]),int(text_block["width"]),int(text_block["height"])
-
-
-            cv2.rectangle(self.__image_blocks, (x, y+2), (x + w, y + h-2), (255, 0, 0), -1)
+        # for text_block in self.__page.text_lines:
+        #     for token in text_block:
+        #         if token.Text=="" or token.width<=3 or token.top>self.__page.page_image.shape[0]/5:
+        #             continue
+        #         if token.Text.strip()=="":
+        #             continue
+        #     x, y, w, h = int(min([t.left for t in text_block])),int(min([t.top for t in text_block])),int(max([t.right for t in text_block])),int(max([t.bottom for t in text_block]))
+        #
+        #
+        #     cv2.rectangle(self.__image_blocks, (x, y+2), (w, h-2), (255, 0, 0), -1)
 
     def extract_regions(self):
 
         if not hasattr(self, '__image_blocks'):
             self.analyze_page()
 
         if self.__debug:
```

## pdf2txt/doc_analyzer/imageprocessor.py

```diff
@@ -110,14 +110,16 @@
 
         m = cv.getRotationMatrix2D((cx, cy), ang, 1.0)
         self.__img = cv.warpAffine(
             self.__img, m, (self.__img.shape[1], self.__img.shape[0]))
 
     def __put_back_removed_lines(self, clusters):
         for cluster in clusters:
+            if len(cluster)<=3:
+                continue
             for l in cluster:
                 length = l[2] - l[0]
                 if length > 20:
                     cv.line(self.__img, (l[0] + 5, l[1]), (l[2] - 5, l[3]), (255, 255, 255), 5, cv.LINE_AA)
 
         if self.__debug:
             iu.show_and_wait('Lines detection', self.__img)
@@ -229,16 +231,16 @@
     def ___remove_large_lines(self):
 
         kernel = np.ones((3, 5), np.uint8)
         self.__img= cv.dilate(self.__img,kernel, iterations=1)
 
         if self.__debug:
             iu.show_and_wait('dilated', self.__img)
-        vertical_kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, int(self.image_h*0.15)))
-        horizontal_kernel = cv.getStructuringElement(cv.MORPH_RECT, (int(self.image_w*0.5 ), 3))
+        vertical_kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, int(self.image_h*0.1)))
+        horizontal_kernel = cv.getStructuringElement(cv.MORPH_RECT, (int(self.image_w*0.2 ), 3))
         horizontal_mask = cv.morphologyEx(self.__img, cv.MORPH_OPEN, horizontal_kernel, iterations=1)
 
         vertical_mask = cv.morphologyEx(self.__img, cv.MORPH_OPEN, vertical_kernel, iterations=1)
 
 
         total_mask = cv.bitwise_or(horizontal_mask, vertical_mask)
         if self.__debug:
```

## pdf2txt/doc_analyzer/img.py

```diff
@@ -3,15 +3,25 @@
 import math
 
 
 
 def show_rects_and_wait(rects, image, title="", color=(255, 0, 0)):
 
     for graph in rects:
-        cv.rectangle(image, (int(graph.left), int(graph.top)), (int(graph.right), int(graph.bottom)), color,4)
+        try:
+            cv.rectangle(image, (int(graph.left), int(graph.top)), (int(graph.right), int(graph.bottom)), color,4)
+        except Exception as e:
+            try:
+                cv.rectangle(image, (int(graph["left"]), int(graph["top"])), (int(graph["right"]), int(graph["bottom"])),
+                             color, 4)
+            except:
+                cv.rectangle(image, (int(graph[0]), int(graph[1])), (int(graph[2]), int(graph[3])),
+                             color, 4)
+
+
     show_and_wait(title, image)
 
 
 def show_and_wait(title, img):
     cv.namedWindow(title, cv.WINDOW_KEEPRATIO)
     cv.imshow(title, img)
     if cv.waitKey(0):  # & 0xff == 27:
```

## pdf2txt/doc_analyzer/region.py

```diff
@@ -2,16 +2,16 @@
 import cv2
 from scipy import ndimage
 from pdf2txt.core.tree import Node
 import pdf2txt.doc_analyzer.img as iu
 from pdf2txt.utils import BoundingBox, is_ovarlaping_with_objects
 
 DEFAULT_X_SEPARATOR_WIDTH_RATIO=0.004
-DEFAULT_Y_SEPARATOR_HEIGHT_RATIO=0.0035
-MIN_HEADER_FOOTER_HEIGHT=0.08
+DEFAULT_Y_SEPARATOR_HEIGHT_RATIO=0.004
+MIN_HEADER_FOOTER_HEIGHT=0.12
 MIN_AREA_HIEGHT_RATIO=0.06
 MIN_AREA_WIDTH_RATIO=0.24
 
 class RegionExtractor:
     h_separator_size = DEFAULT_X_SEPARATOR_WIDTH_RATIO
     v_separator_size = DEFAULT_Y_SEPARATOR_HEIGHT_RATIO
 
@@ -81,15 +81,15 @@
         splits = self._split_region_vertical(page, area=bbox, min_width=int(MIN_AREA_WIDTH_RATIO*page.shape[1]))
 
         if splits !=(None, None):
             return splits
 
         splits = self._split_region_horizental(page, area=bbox, min_height=int(MIN_HEADER_FOOTER_HEIGHT*page.shape[0]))
         if splits != (None, None):
-            splits2=self._split_region_horizental(page, area=splits[1], min_height=int((MIN_HEADER_FOOTER_HEIGHT*page.shape[0])/2))
+            splits2=self._split_region_vertical(page, area=bbox, min_width=int(MIN_AREA_WIDTH_RATIO*page.shape[1]))
 
             if splits2 !=(None, None):
                 splits=list(splits)
                 splits[1]=splits2[0]
                 splits.append(splits2[1])
 
 
@@ -139,21 +139,23 @@
         if len(split_indices) > 0:
             indices = np.where(labels == split_indices[0] + 1)
             i=0
             split_y = indices[0][int(len(indices[0]) / 2)]
             height_above=split_y
             height_below=area.bottom-(area.top+split_y)
 
-            while (i < len(split_indices)) and(len(indices[0]) < self.h_separator_size or (height_above<min_height or height_below<min_height)):
+            while (i < len(split_indices)) and (len(indices[0]) < self.h_separator_size or (height_above<min_height or height_below<min_height)):
+                # if len(indices[0]) > 2*self.h_separator_size:
+                #     break
                 indices = np.where(labels == split_indices[i] + 1)
                 split_y = indices[0][int(len(indices[0]) / 2)]
                 height_above = split_y
                 height_below = area.bottom - (area.top + split_y)
                 i+=1
-            if i==len(split_indices) and (len(indices[0]) >= self.h_separator_size and (height_above>=min_height and height_below>=min_height)):
+            if i==len(split_indices) and (len(indices[0]) >= self.h_separator_size and (height_above>=min_height and height_below>=min_height)) or len(indices[0]) >= 2*self.h_separator_size:
                 pass
             elif i>= len(split_indices):
                 return r1, r2
 
 
 
             r1 = BoundingBox(top=area.top, left=area.left, right=area.right,
```

